Log file open, 01/08/26 01:27:52
LogWindows: Failed to load 'aqProf.dll' (GetLastError=126)
LogWindows: File 'aqProf.dll' does not exist
LogProfilingDebugging: Loading WinPixEventRuntime.dll for PIX profiling (from ../../../Engine/Binaries/ThirdParty/Windows/WinPixEventRuntime/x64).
LogWindows: Failed to load 'VtuneApi.dll' (GetLastError=126)
LogWindows: File 'VtuneApi.dll' does not exist
LogWindows: Failed to load 'VtuneApi32e.dll' (GetLastError=126)
LogWindows: File 'VtuneApi32e.dll' does not exist
LogWindows: Custom abort handler registered for crash reporting.
LogCore: Display: UTS: The Unreal Trace Server binary is not available ('../../../Engine/Binaries/Win64/UnrealTraceServer.exe')
LogTrace: Initializing trace...
LogTrace: Finished trace initialization.
LogCsvProfiler: Display: Metadata set : platform="Windows"
LogCsvProfiler: Display: Metadata set : config="Development"
LogCsvProfiler: Display: Metadata set : buildversion="++UE5+Release-5.6-CL-44394996"
LogCsvProfiler: Display: Metadata set : engineversion="5.6.1-44394996+++UE5+Release-5.6"
LogCsvProfiler: Display: Metadata set : os="Windows 10 (22H2) [10.0.19045.6456] "
LogCsvProfiler: Display: Metadata set : cpu="AuthenticAMD|AMD Ryzen 9 5900X 12-Core Processor"
LogCsvProfiler: Display: Metadata set : pgoenabled="0"
LogCsvProfiler: Display: Metadata set : pgoprofilingenabled="0"
LogCsvProfiler: Display: Metadata set : ltoenabled="0"
LogCsvProfiler: Display: Metadata set : asan="0"
LogCsvProfiler: Display: Metadata set : commandline="" CoopGameFleep P_LearningAgentsTrial1 -headless-training -nullrhi -nosound -log -log=special_aggressive_seed_1801914551.log -unattended -nothreading -NoVerifyGC -NoLoadStartupPackages -FORCELOGFLUSH -ini:Engine:[Core.Log]:LogPython=Verbose -RandomSeed=1801914551 -LearningRatePolicy=0.0003 -LearningRateCritic=0.003 -EpsilonClip=0.3 -PolicyBatchSize=2048 -CriticBatchSize=8192 -IterationsPerGather=64 -NumberOfIterations=1000000 -DiscountFactor=0.995 -GaeLambda=0.95 -ActionEntropyWeight=0 -UseObstacles=False -MaxObstacles=8 -MinObstacleSize=100 -MaxObstacleSize=300 -ObstacleMode=Static -TrainingTaskName=Aggressive-seed-1801914551-750b6e4caaa0""
LogCsvProfiler: Display: Metadata set : loginid="a22046ef4d92c3e541815b8ee0aac772"
LogCsvProfiler: Display: Metadata set : llm="0"
LogPakFile: Initializing PakPlatformFile
LogIoDispatcher: Display: Reading toc: ../../../CoopGameFleep/Content/Paks/global.utoc
LogIoDispatcher: Display: Toc loaded : ../../../CoopGameFleep/Content/Paks/global.utoc, Id=ffffffffffffffff, Order=0, EntryCount=1, SignatureHash=0000000000000000000000000000000000000000
LogIoDispatcher: Display: Mounting container '../../../CoopGameFleep/Content/Paks/global.utoc' in location slot 0
LogPakFile: Display: Initialized I/O dispatcher file backend. Mounted the global container: ../../../CoopGameFleep/Content/Paks/global.utoc
LogPakFile: Display: Found Pak file ../../../CoopGameFleep/Content/Paks/CoopGameFleep-Windows.pak attempting to mount.
LogPakFile: Display: Mounting pak file ../../../CoopGameFleep/Content/Paks/CoopGameFleep-Windows.pak.
LogIoDispatcher: Display: Reading toc: ../../../CoopGameFleep/Content/Paks/CoopGameFleep-Windows.utoc
LogIoDispatcher: Display: Toc loaded : ../../../CoopGameFleep/Content/Paks/CoopGameFleep-Windows.utoc, Id=aa73602243d5c2d2, Order=4, EntryCount=1167, SignatureHash=0000000000000000000000000000000000000000
LogIoDispatcher: Display: Mounting container '../../../CoopGameFleep/Content/Paks/CoopGameFleep-Windows.utoc' in location slot 0
LogPakFile: Display: Mounted IoStore container "../../../CoopGameFleep/Content/Paks/CoopGameFleep-Windows.utoc"
LogFilePackageStore: Mounting container: Id=aa73602243d5c2d2, Order=4, NumPackages=529
LogPakFile: Display: Mounted Pak file '../../../CoopGameFleep/Content/Paks/CoopGameFleep-Windows.pak', mount point: '../../../'
LogStats: Stats thread started at 0.118812
LogCsvProfiler: Display: Metadata set : systemresolution.resx="1280"
LogCsvProfiler: Display: Metadata set : systemresolution.resy="720"
LogICUInternationalization: OS requested locale 'pt-PT' is not supported. Using the OS requested language of 'en-US' as the locale.
LogICUInternationalization: ICU TimeZone Detection - Raw Offset: +0:00, Platform Override: ''
LogInit: Session CrashGUID >====================================================
         Session CrashGUID >   UECC-Windows-FAD40CF04873C58CBB01D6A66B3EC0DA
         Session CrashGUID >====================================================
LogConfig: No local boot hotfix file found at: [../../../CoopGameFleep/Saved/PersistentDownloadDir/HotfixForNextBoot.txt]
LogAudio: Display: Audio Device Manager not initializing due to all audio being disabled. If this is not intentional, please check command line arguments for "-nosound".
LogPluginManager: Mounting Engine plugin Paper2D
LogPluginManager: Mounting Engine plugin AISupport
LogPluginManager: Mounting Engine plugin EnvironmentQueryEditor
LogPluginManager: Mounting Engine plugin ACLPlugin
LogPluginManager: Mounting Engine plugin AnimationData
LogPluginManager: Mounting Engine plugin ControlRigModules
LogPluginManager: Mounting Engine plugin ControlRigSpline
LogPluginManager: Mounting Engine plugin ControlRig
LogPluginManager: Mounting Engine plugin DeformerGraph
LogPluginManager: Mounting Engine plugin IKRig
LogPluginManager: Mounting Engine plugin RigLogic
LogPluginManager: Mounting Engine plugin SkeletalMeshModelingTools
LogPluginManager: Mounting Engine plugin TweeningUtils
LogPluginManager: Mounting Engine plugin CameraShakePreviewer
LogPluginManager: Mounting Engine plugin EngineCameras
LogPluginManager: Mounting Engine plugin GameplayCameras
LogPluginManager: Mounting Engine plugin ChaosVD
LogPluginManager: Mounting Engine plugin OodleNetwork
LogPluginManager: Mounting Engine plugin AnimationSharing
LogPluginManager: Mounting Engine plugin DumpGPUServices
LogPluginManager: Mounting Engine plugin NamingTokens
LogPluginManager: Mounting Engine plugin PixWinPlugin
LogPluginManager: Mounting Engine plugin PluginUtils
LogPluginManager: Mounting Engine plugin RenderDocPlugin
LogPluginManager: Mounting Engine plugin UObjectPlugin
LogPluginManager: Mounting Engine plugin AssetManagerEditor
LogPluginManager: Mounting Engine plugin BlueprintHeaderView
LogPluginManager: Mounting Engine plugin ColorGrading
LogPluginManager: Mounting Engine plugin ContentBrowserAssetDataSource
LogPluginManager: Mounting Engine plugin CurveEditorTools
LogPluginManager: Mounting Engine plugin DataValidation
LogPluginManager: Mounting Engine plugin EditorScriptingUtilities
LogPluginManager: Mounting Engine plugin EngineAssetDefinitions
LogPluginManager: Mounting Engine plugin FacialAnimation
LogPluginManager: Mounting Engine plugin GeometryMode
LogPluginManager: Mounting Engine plugin LightMixer
LogPluginManager: Mounting Engine plugin ObjectMixer
LogPluginManager: Mounting Engine plugin SequencerAnimTools
LogPluginManager: Mounting Engine plugin UMGWidgetPreview
LogPluginManager: Mounting Engine plugin UVEditor
LogPluginManager: Mounting Engine plugin EnhancedInput
LogPluginManager: Mounting Engine plugin DatasmithContent
LogPluginManager: Mounting Engine plugin GLTFExporter
LogPluginManager: Mounting Engine plugin VariantManagerContent
LogPluginManager: Mounting Engine plugin VariantManager
LogPluginManager: Mounting Engine plugin AutomationUtils
LogPluginManager: Mounting Engine plugin BackChannel
LogPluginManager: Mounting Engine plugin ChaosCaching
LogPluginManager: Mounting Engine plugin ChaosUserDataPT
LogPluginManager: Mounting Engine plugin CharacterAI
LogPluginManager: Mounting Engine plugin CompositeCore
LogPluginManager: Mounting Engine plugin Dataflow
LogPluginManager: Mounting Engine plugin EditorDataStorageFeatures
LogPluginManager: Mounting Engine plugin EditorDataStorage
LogPluginManager: Mounting Engine plugin FullBodyIK
LogPluginManager: Mounting Engine plugin LearningAgents
LogPluginManager: Mounting Engine plugin LevelSequenceNavigatorBridge
LogPluginManager: Mounting Engine plugin LocalizableMessage
LogPluginManager: Mounting Engine plugin NFORDenoise
LogPluginManager: Mounting Engine plugin NNERuntimeBasicCpu
LogPluginManager: Mounting Engine plugin PlatformCrypto
LogPluginManager: Mounting Engine plugin PythonFoundationPackages
LogPluginManager: Mounting Engine plugin PythonScriptPlugin
LogPluginManager: Mounting Engine plugin RuntimeTelemetry
LogPluginManager: Mounting Engine plugin Tensorboard
LogPluginManager: Mounting Engine plugin ToolPresets
LogPluginManager: Mounting Engine plugin Cascade
LogPluginManager: Mounting Engine plugin NiagaraSimCaching
LogPluginManager: Mounting Engine plugin Niagara
LogPluginManager: Mounting Engine plugin Fab
LogPluginManager: Mounting Engine plugin InterchangeAssets
LogPluginManager: Mounting Engine plugin Interchange
LogPluginManager: Mounting Engine plugin AvfMedia
LogPluginManager: Mounting Engine plugin ImgMedia
LogPluginManager: Mounting Engine plugin MediaCompositing
LogPluginManager: Mounting Engine plugin MediaPlate
LogPluginManager: Mounting Engine plugin TcpMessaging
LogPluginManager: Mounting Engine plugin UdpMessaging
LogPluginManager: Mounting Engine plugin MetaHumanSDK
LogPluginManager: Mounting Engine plugin ActorSequence
LogPluginManager: Mounting Engine plugin LevelSequenceEditor
LogPluginManager: Mounting Engine plugin SequencerScripting
LogPluginManager: Mounting Engine plugin TemplateSequence
LogPluginManager: Mounting Engine plugin NNEDenoiser
LogPluginManager: Mounting Engine plugin NNERuntimeORT
LogPluginManager: Mounting Engine plugin LauncherChunkInstaller
LogPluginManager: Mounting Engine plugin ActorLayerUtilities
LogPluginManager: Mounting Engine plugin ArchVisCharacter
LogPluginManager: Mounting Engine plugin AssetTags
LogPluginManager: Mounting Engine plugin AudioCapture
LogPluginManager: Mounting Engine plugin AudioSynesthesia
LogPluginManager: Mounting Engine plugin CableComponent
LogPluginManager: Mounting Engine plugin ChunkDownloader
LogPluginManager: Mounting Engine plugin ComputeFramework
LogPluginManager: Mounting Engine plugin CustomMeshComponent
LogPluginManager: Mounting Engine plugin ExampleDeviceProfileSelector
LogPluginManager: Mounting Engine plugin GeometryCache
LogPluginManager: Mounting Engine plugin GeometryProcessing
LogPluginManager: Mounting Engine plugin HairStrands
LogPluginManager: Mounting Engine plugin InputDebugging
LogPluginManager: Mounting Engine plugin MsQuic
LogPluginManager: Mounting Engine plugin ProceduralMeshComponent
LogPluginManager: Mounting Engine plugin PropertyAccessEditor
LogPluginManager: Mounting Engine plugin PropertyBindingUtils
LogPluginManager: Mounting Engine plugin RigVM
LogPluginManager: Mounting Engine plugin SignificanceManager
LogPluginManager: Mounting Engine plugin SoundFields
LogPluginManager: Mounting Engine plugin StateTree
LogPluginManager: Mounting Engine plugin Synthesis
LogPluginManager: Mounting Engine plugin WindowsDeviceProfileSelector
LogPluginManager: Mounting Engine plugin XInputDevice
LogPluginManager: Mounting Engine plugin FunctionalTestingEditor
LogPluginManager: Mounting Engine plugin TraceUtilities
LogPluginManager: Mounting Engine plugin CameraCalibrationCore
LogPluginManager: Mounting Engine plugin Takes
LogPluginManager: Mounting Engine plugin WorldMetrics
LogHAL: Log category LogPython verbosity has been raised to Verbose.
LogWindows: Failed to load 'WinPixGpuCapturer.dll' (GetLastError=126)
LogWindows: File 'WinPixGpuCapturer.dll' does not exist
PixWinPlugin: PIX capture plugin failed to initialize! Check that the process is launched from PIX.
LogConfig: Applying CVar settings from Section [/Script/RenderDocPlugin.RenderDocPluginSettings] File [Engine]
RenderDocPlugin: Display: RenderDoc plugin will not be loaded. Use '-AttachRenderDoc' on the cmd line or enable 'renderdoc.AutoAttach' in the plugin settings.
LogConfig: Applying CVar settings from Section [/Script/CompositeCore.CompositeCorePluginSettings] File [Engine]
LogNFORDenoise: NFORDenoise function starting up
LogStudioTelemetry: Started StudioTelemetry Session
LogInit: ExecutableName: CoopGameFleep.exe
LogInit: Build: ++UE5+Release-5.6-CL-44394996
LogInit: Platform=Windows
LogInit: MachineId=a22046ef4d92c3e541815b8ee0aac772
LogInit: DeviceId=
LogInit: Engine Version: 5.6.1-44394996+++UE5+Release-5.6
LogInit: Compatible Engine Version: 5.6.0-43139311+++UE5+Release-5.6
LogInit: Net CL: 43139311
LogInit: OS: Windows 10 (22H2) [10.0.19045.6456] (), CPU: AMD Ryzen 9 5900X 12-Core Processor            , GPU: AMD Radeon RX 6650 XT
LogInit: Compiled (64-bit): Jul 28 2025 21:02:46
LogInit: Architecture: x64
LogInit: Compiled with Visual C++: 19.38.33130.00
LogInit: Build Configuration: Development
LogInit: Branch Name: ++UE5+Release-5.6
LogInit: Command Line: P_LearningAgentsTrial1 -headless-training -nullrhi -nosound -log -log=special_aggressive_seed_1801914551.log -unattended -nothreading -NoVerifyGC -NoLoadStartupPackages -FORCELOGFLUSH -ini:Engine:[Core.Log]:LogPython=Verbose -RandomSeed=1801914551 -LearningRatePolicy=0.0003 -LearningRateCritic=0.003 -EpsilonClip=0.3 -PolicyBatchSize=2048 -CriticBatchSize=8192 -IterationsPerGather=64 -NumberOfIterations=1000000 -DiscountFactor=0.995 -GaeLambda=0.95 -ActionEntropyWeight=0 -UseObstacles=False -MaxObstacles=8 -MinObstacleSize=100 -MaxObstacleSize=300 -ObstacleMode=Static -TrainingTaskName=Aggressive-seed-1801914551-750b6e4caaa0
LogInit: Base Directory: D:/unrealprojects/coop-game-fleep/TrainingBuild/Windows/CoopGameFleep/Binaries/Win64/
LogInit: Allocator: Binned2
LogInit: Installed Engine Build: 0
LogInit: This binary is optimized with LTO: no, PGO: no, instrumented for PGO data collection: no
LogDevObjectVersion: Number of dev versions registered: 42
LogDevObjectVersion:   Dev-Blueprints (B0D832E4-1F89-4F0D-ACCF-7EB736FD4AA2): 10
LogDevObjectVersion:   Dev-Build (E1C64328-A22C-4D53-A36C-8E866417BD8C): 0
LogDevObjectVersion:   Dev-Core (375EC13C-06E4-48FB-B500-84F0262A717E): 4
LogDevObjectVersion:   Dev-Editor (E4B068ED-F494-42E9-A231-DA0B2E46BB41): 40
LogDevObjectVersion:   Dev-Framework (CFFC743F-43B0-4480-9391-14DF171D2073): 37
LogDevObjectVersion:   Dev-Mobile (B02B49B5-BB20-44E9-A304-32B752E40360): 3
LogDevObjectVersion:   Dev-Networking (A4E4105C-59A1-49B5-A7C5-40C4547EDFEE): 0
LogDevObjectVersion:   Dev-Online (39C831C9-5AE6-47DC-9A44-9C173E1C8E7C): 0
LogDevObjectVersion:   Dev-Physics (78F01B33-EBEA-4F98-B9B4-84EACCB95AA2): 20
LogDevObjectVersion:   Dev-Platform (6631380F-2D4D-43E0-8009-CF276956A95A): 0
LogDevObjectVersion:   Dev-Rendering (12F88B9F-8875-4AFC-A67C-D90C383ABD29): 49
LogDevObjectVersion:   Dev-Sequencer (7B5AE74C-D270-4C10-A958-57980B212A5A): 13
LogDevObjectVersion:   Dev-VR (D7296918-1DD6-4BDD-9DE2-64A83CC13884): 3
LogDevObjectVersion:   Dev-LoadTimes (C2A15278-BFE7-4AFE-6C17-90FF531DF755): 1
LogDevObjectVersion:   Private-Geometry (6EACA3D4-40EC-4CC1-B786-8BED09428FC5): 3
LogDevObjectVersion:   Dev-AnimPhys (29E575DD-E0A3-4627-9D10-D276232CDCEA): 17
LogDevObjectVersion:   Dev-Anim (AF43A65D-7FD3-4947-9873-3E8ED9C1BB05): 15
LogDevObjectVersion:   Dev-ReflectionCapture (6B266CEC-1EC7-4B8F-A30B-E4D90942FC07): 1
LogDevObjectVersion:   Dev-Automation (0DF73D61-A23F-47EA-B727-89E90C41499A): 1
LogDevObjectVersion:   FortniteMain (601D1886-AC64-4F84-AA16-D3DE0DEAC7D6): 207
LogDevObjectVersion:   FortniteValkyrie (8DBC2C5B-54A7-43E0-A768-FCBB7DA29060): 8
LogDevObjectVersion:   FortniteSeason (5B4C06B7-2463-4AF8-805B-BF70CDF5D0DD): 13
LogDevObjectVersion:   FortniteRelease (E7086368-6B23-4C58-8439-1B7016265E91): 17
LogDevObjectVersion:   Dev-Enterprise (9DFFBCD6-494F-0158-E221-12823C92A888): 11
LogDevObjectVersion:   Dev-Niagara (F2AED0AC-9AFE-416F-8664-AA7FFA26D6FC): 1
LogDevObjectVersion:   Dev-Destruction (174F1F0B-B4C6-45A5-B13F-2EE8D0FB917D): 10
LogDevObjectVersion:   Dev-Physics-Ext (35F94A83-E258-406C-A318-09F59610247C): 41
LogDevObjectVersion:   Dev-PhysicsMaterial-Chaos (B68FC16E-8B1B-42E2-B453-215C058844FE): 1
LogDevObjectVersion:   Dev-CineCamera (B2E18506-4273-CFC2-A54E-F4BB758BBA07): 1
LogDevObjectVersion:   Dev-VirtualProduction (64F58936-FD1B-42BA-BA96-7289D5D0FA4E): 1
LogDevObjectVersion:   UE5-Main (697DD581-E64F-41AB-AA4A-51ECBEB7B628): 121
LogDevObjectVersion:   UE5-Release (D89B5E42-24BD-4D46-8412-ACA8DF641779): 56
LogDevObjectVersion:   UE5-SpecialProject (59DA5D52-1232-4948-B878-597870B8E98B): 9
LogDevObjectVersion:   Dev-MediaFramework (6F0ED827-A609-4895-9C91-998D90180EA4): 2
LogDevObjectVersion:   Dev-NaniteResearch (30D58BE3-95EA-4282-A6E3-B159D8EBB06A): 1
LogDevObjectVersion:   Dev-RigVM (DC49959B-53C0-4DE7-9156-EA885E7C5D39): 18
LogDevObjectVersion:   Dev-ControlRig (A7820CFB-20A7-4359-8C54-2C149623CF50): 38
LogDevObjectVersion:   Dev-IKRig (F6DFBB78-BB50-A0E4-4018-B84D60CBAF23): 6
LogDevObjectVersion:   LensFileVersion (8652A554-966A-466C-9FD7-1C6DD61B1ADB): 1
LogDevObjectVersion:   FN-Main-InterchangePipeline (B69D2E47-E2A8-4003-BF77-18A492C4D899): 1
LogDevObjectVersion:   Dev-ComputeFramework (6304A3E7-0059-4F59-8CFC-21BD7721FD4E): 0
LogDevObjectVersion:   Dev-Optimus (93EDE1AA-10CA-7375-4DF9-8A2849B157A0): 14
LogInit: Presizing for max 2097152 objects, including 1 objects not considered by GC.
LogInit: Object subsystem initialized
LogConfig: Set CVar [[con.DebugEarlyDefault:1]]
LogConfig: CVar [[con.DebugLateDefault:1]] deferred - dummy variable created
LogConfig: CVar [[con.DebugLateCheat:1]] deferred - dummy variable created
LogConfig: CVar [[LogNamedEventFilters:Frame *]] deferred - dummy variable created
LogConfig: Set CVar [[r.setres:1280x720]]
LogConfig: CVar [[framepro.ScopeMinTimeMicroseconds:10]] deferred - dummy variable created
LogConfig: Set CVar [[fx.NiagaraAllowRuntimeScalabilityChanges:1]]
LogConfig: CVar [[QualityLevelMapping:high]] deferred - dummy variable created
LogConfig: CVar [[r.Occlusion.SingleRHIThreadStall:1]] deferred - dummy variable created
LogConfig: Set CVar [[r.Nanite.Streaming.ReservedResources:1]]
LogConfig: Set CVar [[D3D12.Bindless.ResourceDescriptorHeapSize:32768]]
LogConfig: Set CVar [[D3D12.Bindless.SamplerDescriptorHeapSize:2048]]
LogConfig: Set CVar [[r.PSOPrecache.GlobalShaders:1]]
LogConfig: Set CVar [[r.VRS.EnableSoftware:1]]
LogConfig: Set CVar [[r.VRS.ContrastAdaptiveShading:1]]
[2026.01.08-01.27.53:492][  0]LogConfig: CVar [[con.DebugLateDefault:1]] deferred - dummy variable created
[2026.01.08-01.27.53:496][  0]LogConfig: CVar [[con.DebugLateCheat:1]] deferred - dummy variable created
[2026.01.08-01.27.53:501][  0]LogConfig: CVar [[LogNamedEventFilters:Frame *]] deferred - dummy variable created
[2026.01.08-01.27.53:505][  0]LogConfig: CVar [[framepro.ScopeMinTimeMicroseconds:10]] deferred - dummy variable created
[2026.01.08-01.27.53:512][  0]LogConfig: CVar [[QualityLevelMapping:high]] deferred - dummy variable created
[2026.01.08-01.27.53:517][  0]LogConfig: CVar [[r.Occlusion.SingleRHIThreadStall:1]] deferred - dummy variable created
[2026.01.08-01.27.53:524][  0]LogConfig: Applying CVar settings from Section [/Script/Engine.RendererSettings] File [Engine]
[2026.01.08-01.27.53:529][  0]LogConfig: CVar [[VisualizeCalibrationColorMaterialPath:/Engine/EngineMaterials/PPM_DefaultCalibrationColor.PPM_DefaultCalibrationColor]] deferred - dummy variable created
[2026.01.08-01.27.53:534][  0]LogConfig: CVar [[VisualizeCalibrationGrayscaleMaterialPath:/Engine/EngineMaterials/PPM_DefaultCalibrationGrayscale.PPM_DefaultCalibrationGrayscale]] deferred - dummy variable created
[2026.01.08-01.27.53:538][  0]LogConfig: Set CVar [[r.GPUCrashDebugging:0]]
[2026.01.08-01.27.53:541][  0]LogConfig: CVar [[MaxSkinBones:(Default=65536,PerPlatform=(("Mobile", 256)))]] deferred - dummy variable created
[2026.01.08-01.27.53:546][  0]LogConfig: Set CVar [[r.Shaders.RemoveUnusedInterpolators:1]]
[2026.01.08-01.27.53:550][  0]LogConfig: Set CVar [[r.Shadow.DetectVertexShaderLayerAtRuntime:1]]
[2026.01.08-01.27.53:555][  0]LogConfig: Set CVar [[r.ReflectionMethod:0]]
[2026.01.08-01.27.53:559][  0]LogConfig: Applying CVar settings from Section [/Script/Engine.RendererOverrideSettings] File [Engine]
[2026.01.08-01.27.53:563][  0]LogConfig: Applying CVar settings from Section [/Script/Engine.StreamingSettings] File [Engine]
[2026.01.08-01.27.53:568][  0]LogConfig: Set CVar [[s.MinBulkDataSizeForAsyncLoading:131072]]
[2026.01.08-01.27.53:571][  0]LogConfig: Set CVar [[s.AsyncLoadingThreadEnabled:1]]
[2026.01.08-01.27.53:575][  0]LogConfig: Set CVar [[s.EventDrivenLoaderEnabled:1]]
[2026.01.08-01.27.53:579][  0]LogConfig: Set CVar [[s.WarnIfTimeLimitExceeded:0]]
[2026.01.08-01.27.53:587][  0]LogConfig: Set CVar [[s.TimeLimitExceededMultiplier:1.5]]
[2026.01.08-01.27.53:590][  0]LogConfig: Set CVar [[s.TimeLimitExceededMinTime:0.005]]
[2026.01.08-01.27.53:594][  0]LogConfig: Set CVar [[s.UseBackgroundLevelStreaming:1]]
[2026.01.08-01.27.53:598][  0]LogConfig: Set CVar [[s.PriorityAsyncLoadingExtraTime:15.0]]
[2026.01.08-01.27.53:602][  0]LogConfig: Set CVar [[s.LevelStreamingActorsUpdateTimeLimit:5.0]]
[2026.01.08-01.27.53:603][  0]LogConfig: Set CVar [[s.PriorityLevelStreamingActorsUpdateExtraTime:5.0]]
[2026.01.08-01.27.53:607][  0]LogConfig: Set CVar [[s.LevelStreamingComponentsRegistrationGranularity:10]]
[2026.01.08-01.27.53:610][  0]LogConfig: Set CVar [[s.UnregisterComponentsTimeLimit:1.0]]
[2026.01.08-01.27.53:614][  0]LogConfig: Set CVar [[s.LevelStreamingComponentsUnregistrationGranularity:5]]
[2026.01.08-01.27.53:618][  0]LogConfig: CVar [[s.MaxPackageSummarySize:16384]] deferred - dummy variable created
[2026.01.08-01.27.53:621][  0]LogConfig: Set CVar [[s.FlushStreamingOnExit:1]]
[2026.01.08-01.27.53:625][  0]LogConfig: CVar [[FixedBootOrder:/Script/Engine/Default__SoundBase]] deferred - dummy variable created
[2026.01.08-01.27.53:630][  0]LogConfig: CVar [[FixedBootOrder:/Script/Engine/Default__MaterialInterface]] deferred - dummy variable created
[2026.01.08-01.27.53:634][  0]LogConfig: CVar [[FixedBootOrder:/Script/Engine/Default__DeviceProfileManager]] deferred - dummy variable created
[2026.01.08-01.27.53:639][  0]LogConfig: Applying CVar settings from Section [/Script/Engine.GarbageCollectionSettings] File [Engine]
[2026.01.08-01.27.53:643][  0]LogConfig: Set CVar [[gc.MaxObjectsNotConsideredByGC:1]]
[2026.01.08-01.27.53:648][  0]LogConfig: Set CVar [[gc.FlushStreamingOnGC:0]]
[2026.01.08-01.27.53:652][  0]LogConfig: Set CVar [[gc.NumRetriesBeforeForcingGC:10]]
[2026.01.08-01.27.53:658][  0]LogConfig: Set CVar [[gc.AllowParallelGC:1]]
[2026.01.08-01.27.53:662][  0]LogConfig: Set CVar [[gc.TimeBetweenPurgingPendingKillObjects:61.1]]
[2026.01.08-01.27.53:667][  0]LogConfig: Set CVar [[gc.MaxObjectsInEditor:25165824]]
[2026.01.08-01.27.53:693][  0]LogConfig: Set CVar [[gc.IncrementalBeginDestroyEnabled:1]]
[2026.01.08-01.27.53:699][  0]LogConfig: Set CVar [[gc.CreateGCClusters:1]]
[2026.01.08-01.27.53:704][  0]LogConfig: Set CVar [[gc.MinGCClusterSize:5]]
[2026.01.08-01.27.53:710][  0]LogConfig: Set CVar [[gc.AssetClustreringEnabled:0]]
[2026.01.08-01.27.53:714][  0]LogConfig: Set CVar [[gc.ActorClusteringEnabled:0]]
[2026.01.08-01.27.53:718][  0]LogConfig: Set CVar [[gc.VerifyUObjectsAreNotFGCObjects:0]]
[2026.01.08-01.27.53:722][  0]LogConfig: Set CVar [[gc.GarbageEliminationEnabled:1]]
[2026.01.08-01.27.53:726][  0]LogConfig: Applying CVar settings from Section [/Script/Engine.NetworkSettings] File [Engine]
[2026.01.08-01.27.53:730][  0]LogConfig: CVar [[NetworkEmulationProfiles:(ProfileName="Average",ToolTip="Simulates average internet conditions")]] deferred - dummy variable created
[2026.01.08-01.27.53:734][  0]LogConfig: CVar [[NetworkEmulationProfiles:(ProfileName="Bad",ToolTip="Simulates laggy internet conditions")]] deferred - dummy variable created
[2026.01.08-01.27.53:767][  0]LogCsvProfiler: Display: Metadata set : systemresolution.resx="2560"
[2026.01.08-01.27.53:779][  0]LogCsvProfiler: Display: Metadata set : systemresolution.resy="1440"
[2026.01.08-01.27.53:785][  0]LogConfig: Applying CVar settings from Section [ViewDistanceQuality@3] File [Scalability]
[2026.01.08-01.27.53:793][  0]LogConfig: Set CVar [[r.SkeletalMeshLODBias:0]]
[2026.01.08-01.27.53:796][  0]LogConfig: Set CVar [[r.ViewDistanceScale:1.0]]
[2026.01.08-01.27.53:800][  0]LogConfig: Applying CVar settings from Section [AntiAliasingQuality@3] File [Scalability]
[2026.01.08-01.27.53:804][  0]LogConfig: Set CVar [[r.FXAA.Quality:4]]
[2026.01.08-01.27.53:809][  0]LogConfig: Set CVar [[r.TemporalAA.Quality:2]]
[2026.01.08-01.27.53:813][  0]LogConfig: Set CVar [[r.TSR.History.R11G11B10:1]]
[2026.01.08-01.27.53:818][  0]LogConfig: Set CVar [[r.TSR.History.ScreenPercentage:200]]
[2026.01.08-01.27.53:823][  0]LogConfig: Set CVar [[r.TSR.History.UpdateQuality:3]]
[2026.01.08-01.27.53:830][  0]LogConfig: Set CVar [[r.TSR.ShadingRejection.Flickering:1]]
[2026.01.08-01.27.53:835][  0]LogConfig: Set CVar [[r.TSR.RejectionAntiAliasingQuality:2]]
[2026.01.08-01.27.53:840][  0]LogConfig: Set CVar [[r.TSR.ReprojectionField:1]]
[2026.01.08-01.27.53:846][  0]LogConfig: Set CVar [[r.TSR.Resurrection:1]]
[2026.01.08-01.27.53:851][  0]LogConfig: Applying CVar settings from Section [ShadowQuality@3] File [Scalability]
[2026.01.08-01.27.53:856][  0]LogConfig: Set CVar [[r.LightFunctionQuality:1]]
[2026.01.08-01.27.53:860][  0]LogConfig: Set CVar [[r.ShadowQuality:5]]
[2026.01.08-01.27.53:865][  0]LogConfig: Set CVar [[r.Shadow.CSM.MaxCascades:10]]
[2026.01.08-01.27.53:869][  0]LogConfig: Set CVar [[r.Shadow.MaxResolution:2048]]
[2026.01.08-01.27.53:874][  0]LogConfig: Set CVar [[r.Shadow.MaxCSMResolution:2048]]
[2026.01.08-01.27.53:878][  0]LogConfig: Set CVar [[r.Shadow.RadiusThreshold:0.01]]
[2026.01.08-01.27.53:883][  0]LogConfig: Set CVar [[r.Shadow.DistanceScale:1.0]]
[2026.01.08-01.27.53:888][  0]LogConfig: Set CVar [[r.Shadow.CSM.TransitionScale:1.0]]
[2026.01.08-01.27.53:893][  0]LogConfig: Set CVar [[r.Shadow.PreShadowResolutionFactor:1.0]]
[2026.01.08-01.27.53:899][  0]LogConfig: Set CVar [[r.DistanceFieldShadowing:1]]
[2026.01.08-01.27.53:905][  0]LogConfig: Set CVar [[r.VolumetricFog:1]]
[2026.01.08-01.27.53:909][  0]LogConfig: Set CVar [[r.VolumetricFog.GridPixelSize:8]]
[2026.01.08-01.27.53:914][  0]LogConfig: Set CVar [[r.VolumetricFog.GridSizeZ:128]]
[2026.01.08-01.27.53:921][  0]LogConfig: Set CVar [[r.VolumetricFog.HistoryMissSupersampleCount:4]]
[2026.01.08-01.27.53:926][  0]LogConfig: Set CVar [[r.LightMaxDrawDistanceScale:1]]
[2026.01.08-01.27.53:931][  0]LogConfig: Set CVar [[r.CapsuleShadows:1]]
[2026.01.08-01.27.53:936][  0]LogConfig: Set CVar [[r.Shadow.Virtual.MaxPhysicalPages:4096]]
[2026.01.08-01.27.53:943][  0]LogConfig: Set CVar [[r.Shadow.Virtual.ResolutionLodBiasDirectional:-1.5]]
[2026.01.08-01.27.53:948][  0]LogConfig: Set CVar [[r.Shadow.Virtual.ResolutionLodBiasDirectionalMoving:-1.5]]
[2026.01.08-01.27.53:952][  0]LogConfig: Set CVar [[r.Shadow.Virtual.ResolutionLodBiasLocal:0.0]]
[2026.01.08-01.27.53:956][  0]LogConfig: Set CVar [[r.Shadow.Virtual.ResolutionLodBiasLocalMoving:1.0]]
[2026.01.08-01.27.53:960][  0]LogConfig: Set CVar [[r.Shadow.Virtual.SMRT.RayCountDirectional:8]]
[2026.01.08-01.27.53:964][  0]LogConfig: Set CVar [[r.Shadow.Virtual.SMRT.SamplesPerRayDirectional:4]]
[2026.01.08-01.27.53:969][  0]LogConfig: Set CVar [[r.Shadow.Virtual.SMRT.RayCountLocal:8]]
[2026.01.08-01.27.53:973][  0]LogConfig: Set CVar [[r.Shadow.Virtual.SMRT.SamplesPerRayLocal:4]]
[2026.01.08-01.27.53:978][  0]LogConfig: Applying CVar settings from Section [GlobalIlluminationQuality@3] File [Scalability]
[2026.01.08-01.27.53:985][  0]LogConfig: Set CVar [[r.DistanceFieldAO:1]]
[2026.01.08-01.27.53:994][  0]LogConfig: Set CVar [[r.SkylightIntensityMultiplier:1.0]]
[2026.01.08-01.27.54:002][  0]LogConfig: Set CVar [[r.AOQuality:2]]
[2026.01.08-01.27.54:011][  0]LogConfig: Set CVar [[r.Lumen.DiffuseIndirect.Allow:1]]
[2026.01.08-01.27.54:021][  0]LogConfig: Set CVar [[r.LumenScene.DirectLighting.MaxLightsPerTile:8]]
[2026.01.08-01.27.54:029][  0]LogConfig: Set CVar [[r.LumenScene.DirectLighting.UpdateFactor:32]]
[2026.01.08-01.27.54:035][  0]LogConfig: Set CVar [[r.LumenScene.Radiosity.UpdateFactor:64]]
[2026.01.08-01.27.54:039][  0]LogConfig: Set CVar [[r.LumenScene.Radiosity.ProbeSpacing:4]]
[2026.01.08-01.27.54:044][  0]LogConfig: Set CVar [[r.LumenScene.Radiosity.HemisphereProbeResolution:4]]
[2026.01.08-01.27.54:049][  0]LogConfig: Set CVar [[r.Lumen.TraceMeshSDFs.Allow:1]]
[2026.01.08-01.27.54:054][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.RadianceCache.ProbeResolution:32]]
[2026.01.08-01.27.54:058][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.RadianceCache.NumProbesToTraceBudget:100]]
[2026.01.08-01.27.54:063][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.DownsampleFactor:16]]
[2026.01.08-01.27.54:068][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.NumAdaptiveProbes:8]]
[2026.01.08-01.27.54:074][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.TracingOctahedronResolution:8]]
[2026.01.08-01.27.54:079][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.IrradianceFormat:0]]
[2026.01.08-01.27.54:084][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.StochasticInterpolation:0]]
[2026.01.08-01.27.54:090][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.FullResolutionJitterWidth:1]]
[2026.01.08-01.27.54:095][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.TwoSidedFoliageBackfaceDiffuse:1]]
[2026.01.08-01.27.54:102][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.ScreenTraces.HZBTraversal.FullResDepth:1]]
[2026.01.08-01.27.54:106][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.ShortRangeAO.HardwareRayTracing:0]]
[2026.01.08-01.27.54:111][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.ShortRangeAO.BentNormal:1]]
[2026.01.08-01.27.54:115][  0]LogConfig: Set CVar [[r.Lumen.TranslucencyVolume.GridPixelSize:32]]
[2026.01.08-01.27.54:120][  0]LogConfig: Set CVar [[r.Lumen.TranslucencyVolume.TraceFromVolume:1]]
[2026.01.08-01.27.54:124][  0]LogConfig: Set CVar [[r.Lumen.TranslucencyVolume.TracingOctahedronResolution:3]]
[2026.01.08-01.27.54:129][  0]LogConfig: Set CVar [[r.Lumen.TranslucencyVolume.RadianceCache.ProbeResolution:8]]
[2026.01.08-01.27.54:133][  0]LogConfig: Set CVar [[r.Lumen.TranslucencyVolume.RadianceCache.NumProbesToTraceBudget:70]]
[2026.01.08-01.27.54:138][  0]LogConfig: Set CVar [[r.RayTracing.Scene.BuildMode:1]]
[2026.01.08-01.27.54:144][  0]LogConfig: Applying CVar settings from Section [ReflectionQuality@3] File [Scalability]
[2026.01.08-01.27.54:149][  0]LogConfig: Set CVar [[r.SSR.Quality:3]]
[2026.01.08-01.27.54:154][  0]LogConfig: Set CVar [[r.SSR.HalfResSceneColor:0]]
[2026.01.08-01.27.54:159][  0]LogConfig: Set CVar [[r.Lumen.Reflections.Allow:1]]
[2026.01.08-01.27.54:163][  0]LogConfig: Set CVar [[r.Lumen.Reflections.DownsampleFactor:1]]
[2026.01.08-01.27.54:168][  0]LogConfig: Set CVar [[r.Lumen.Reflections.MaxRoughnessToTraceForFoliage:0.4]]
[2026.01.08-01.27.54:172][  0]LogConfig: Set CVar [[r.Lumen.ScreenProbeGather.MaxRoughnessToEvaluateRoughSpecularForFoliage:0.8]]
[2026.01.08-01.27.54:177][  0]LogConfig: Set CVar [[r.Lumen.Reflections.ScreenSpaceReconstruction.NumSamples:5]]
[2026.01.08-01.27.54:181][  0]LogConfig: Set CVar [[r.Lumen.Reflections.ScreenSpaceReconstruction.MinWeight:0]]
[2026.01.08-01.27.54:186][  0]LogConfig: Set CVar [[r.Lumen.TranslucencyReflections.FrontLayer.Allow:1]]
[2026.01.08-01.27.54:191][  0]LogConfig: Set CVar [[r.Lumen.TranslucencyReflections.FrontLayer.Enable:0]]
[2026.01.08-01.27.54:194][  0]LogConfig: Applying CVar settings from Section [PostProcessQuality@3] File [Scalability]
[2026.01.08-01.27.54:199][  0]LogConfig: Set CVar [[r.MotionBlurQuality:4]]
[2026.01.08-01.27.54:203][  0]LogConfig: Set CVar [[r.MotionBlur.HalfResGather:0]]
[2026.01.08-01.27.54:208][  0]LogConfig: Set CVar [[r.AmbientOcclusionMipLevelFactor:0.4]]
[2026.01.08-01.27.54:211][  0]LogConfig: Set CVar [[r.AmbientOcclusionMaxQuality:100]]
[2026.01.08-01.27.54:215][  0]LogConfig: Set CVar [[r.AmbientOcclusionLevels:-1]]
[2026.01.08-01.27.54:220][  0]LogConfig: Set CVar [[r.AmbientOcclusionRadiusScale:1.0]]
[2026.01.08-01.27.54:224][  0]LogConfig: Set CVar [[r.DepthOfFieldQuality:2]]
[2026.01.08-01.27.54:229][  0]LogConfig: Set CVar [[r.RenderTargetPoolMin:400]]
[2026.01.08-01.27.54:233][  0]LogConfig: Set CVar [[r.LensFlareQuality:2]]
[2026.01.08-01.27.54:240][  0]LogConfig: Set CVar [[r.SceneColorFringeQuality:1]]
[2026.01.08-01.27.54:244][  0]LogConfig: Set CVar [[r.EyeAdaptationQuality:2]]
[2026.01.08-01.27.54:248][  0]LogConfig: Set CVar [[r.BloomQuality:5]]
[2026.01.08-01.27.54:256][  0]LogConfig: Set CVar [[r.Bloom.ScreenPercentage:50.000]]
[2026.01.08-01.27.54:261][  0]LogConfig: Set CVar [[r.FastBlurThreshold:100]]
[2026.01.08-01.27.54:268][  0]LogConfig: Set CVar [[r.Upscale.Quality:3]]
[2026.01.08-01.27.54:272][  0]LogConfig: Set CVar [[r.LightShaftQuality:1]]
[2026.01.08-01.27.54:277][  0]LogConfig: Set CVar [[r.Filter.SizeScale:1]]
[2026.01.08-01.27.54:281][  0]LogConfig: Set CVar [[r.Tonemapper.Quality:5]]
[2026.01.08-01.27.54:288][  0]LogConfig: Set CVar [[r.DOF.Gather.ResolutionDivisor:2         ; lower gathering resolution]]
[2026.01.08-01.27.54:293][  0]LogConfig: Set CVar [[r.DOF.Gather.AccumulatorQuality:1        ; higher gathering accumulator quality]]
[2026.01.08-01.27.54:297][  0]LogConfig: Set CVar [[r.DOF.Gather.PostfilterMethod:1          ; Median3x3 postfilering method]]
[2026.01.08-01.27.54:304][  0]LogConfig: Set CVar [[r.DOF.Gather.EnableBokehSettings:0       ; no bokeh simulation when gathering]]
[2026.01.08-01.27.54:309][  0]LogConfig: Set CVar [[r.DOF.Gather.RingCount:4                 ; medium number of samples when gathering]]
[2026.01.08-01.27.54:313][  0]LogConfig: Set CVar [[r.DOF.Scatter.ForegroundCompositing:1    ; additive foreground scattering]]
[2026.01.08-01.27.54:320][  0]LogConfig: Set CVar [[r.DOF.Scatter.BackgroundCompositing:2    ; additive background scattering]]
[2026.01.08-01.27.54:325][  0]LogConfig: Set CVar [[r.DOF.Scatter.EnableBokehSettings:1      ; bokeh simulation when scattering]]
[2026.01.08-01.27.54:329][  0]LogConfig: Set CVar [[r.DOF.Scatter.MaxSpriteRatio:0.1         ; only a maximum of 10% of scattered bokeh]]
[2026.01.08-01.27.54:335][  0]LogConfig: Set CVar [[r.DOF.Recombine.Quality:1                ; cheap slight out of focus]]
[2026.01.08-01.27.54:338][  0]LogConfig: Set CVar [[r.DOF.Recombine.EnableBokehSettings:0    ; no bokeh simulation on slight out of focus]]
[2026.01.08-01.27.54:343][  0]LogConfig: Set CVar [[r.DOF.TemporalAAQuality:1                ; more stable temporal accumulation]]
[2026.01.08-01.27.54:347][  0]LogConfig: Set CVar [[r.DOF.Kernel.MaxForegroundRadius:0.025]]
[2026.01.08-01.27.54:352][  0]LogConfig: Set CVar [[r.DOF.Kernel.MaxBackgroundRadius:0.025]]
[2026.01.08-01.27.54:356][  0]LogConfig: Applying CVar settings from Section [TextureQuality@3] File [Scalability]
[2026.01.08-01.27.54:361][  0]LogConfig: Set CVar [[r.Streaming.MipBias:0]]
[2026.01.08-01.27.54:364][  0]LogConfig: Set CVar [[r.Streaming.AmortizeCPUToGPUCopy:0]]
[2026.01.08-01.27.54:369][  0]LogConfig: Set CVar [[r.Streaming.MaxNumTexturesToStreamPerFrame:0]]
[2026.01.08-01.27.54:374][  0]LogConfig: Set CVar [[r.Streaming.Boost:1]]
[2026.01.08-01.27.54:379][  0]LogConfig: Set CVar [[r.MaxAnisotropy:8]]
[2026.01.08-01.27.54:383][  0]LogConfig: Set CVar [[r.VT.MaxAnisotropy:8]]
[2026.01.08-01.27.54:388][  0]LogConfig: Set CVar [[r.Streaming.LimitPoolSizeToVRAM:0]]
[2026.01.08-01.27.54:391][  0]LogConfig: Set CVar [[r.Streaming.PoolSize:1000]]
[2026.01.08-01.27.54:396][  0]LogConfig: Set CVar [[r.Streaming.MaxEffectiveScreenSize:0]]
[2026.01.08-01.27.54:400][  0]LogConfig: Applying CVar settings from Section [EffectsQuality@3] File [Scalability]
[2026.01.08-01.27.54:405][  0]LogConfig: Set CVar [[r.TranslucencyLightingVolumeDim:64]]
[2026.01.08-01.27.54:409][  0]LogConfig: Set CVar [[r.RefractionQuality:2]]
[2026.01.08-01.27.54:414][  0]LogConfig: Set CVar [[r.SceneColorFormat:4]]
[2026.01.08-01.27.54:418][  0]LogConfig: Set CVar [[r.DetailMode:3]]
[2026.01.08-01.27.54:424][  0]LogConfig: Set CVar [[r.TranslucencyVolumeBlur:1]]
[2026.01.08-01.27.54:430][  0]LogConfig: Set CVar [[r.MaterialQualityLevel:1 ; High quality]]
[2026.01.08-01.27.54:435][  0]LogConfig: Set CVar [[r.SSS.Scale:1]]
[2026.01.08-01.27.54:440][  0]LogConfig: Set CVar [[r.SSS.SampleSet:2]]
[2026.01.08-01.27.54:445][  0]LogConfig: Set CVar [[r.SSS.Quality:1]]
[2026.01.08-01.27.54:449][  0]LogConfig: Set CVar [[r.SSS.HalfRes:0]]
[2026.01.08-01.27.54:453][  0]LogConfig: Set CVar [[r.SSGI.Quality:3]]
[2026.01.08-01.27.54:458][  0]LogConfig: Set CVar [[r.EmitterSpawnRateScale:1.0]]
[2026.01.08-01.27.54:462][  0]LogConfig: Set CVar [[r.ParticleLightQuality:2]]
[2026.01.08-01.27.54:467][  0]LogConfig: Set CVar [[r.SkyAtmosphere.AerialPerspectiveLUT.FastApplyOnOpaque:1 ; Always have FastSkyLUT 1 in this case to avoid wrong sky]]
[2026.01.08-01.27.54:471][  0]LogConfig: Set CVar [[r.SkyAtmosphere.AerialPerspectiveLUT.SampleCountMaxPerSlice:4]]
[2026.01.08-01.27.54:478][  0]LogConfig: Set CVar [[r.SkyAtmosphere.AerialPerspectiveLUT.DepthResolution:16.0]]
[2026.01.08-01.27.54:482][  0]LogConfig: Set CVar [[r.SkyAtmosphere.FastSkyLUT:1]]
[2026.01.08-01.27.54:487][  0]LogConfig: Set CVar [[r.SkyAtmosphere.FastSkyLUT.SampleCountMin:4.0]]
[2026.01.08-01.27.54:491][  0]LogConfig: Set CVar [[r.SkyAtmosphere.FastSkyLUT.SampleCountMax:128.0]]
[2026.01.08-01.27.54:496][  0]LogConfig: Set CVar [[r.SkyAtmosphere.SampleCountMin:4.0]]
[2026.01.08-01.27.54:499][  0]LogConfig: Set CVar [[r.SkyAtmosphere.SampleCountMax:128.0]]
[2026.01.08-01.27.54:504][  0]LogConfig: Set CVar [[r.SkyAtmosphere.TransmittanceLUT.UseSmallFormat:0]]
[2026.01.08-01.27.54:510][  0]LogConfig: Set CVar [[r.SkyAtmosphere.TransmittanceLUT.SampleCount:10.0]]
[2026.01.08-01.27.54:515][  0]LogConfig: Set CVar [[r.SkyAtmosphere.MultiScatteringLUT.SampleCount:15.0]]
[2026.01.08-01.27.54:518][  0]LogConfig: Set CVar [[fx.Niagara.QualityLevel:3]]
[2026.01.08-01.27.54:523][  0]LogConfig: Set CVar [[r.Refraction.OffsetQuality:1]]
[2026.01.08-01.27.54:527][  0]LogConfig: Set CVar [[r.HeterogeneousVolumes.DownsampleFactor:2]]
[2026.01.08-01.27.54:532][  0]LogConfig: Set CVar [[r.HeterogeneousVolumes.MaxStepCount:256]]
[2026.01.08-01.27.54:536][  0]LogConfig: Set CVar [[r.HeterogeneousVolumes.Shadows.Resolution:256]]
[2026.01.08-01.27.54:541][  0]LogConfig: Set CVar [[r.HeterogeneousVolumes.Shadows.MaxSampleCount:8]]
[2026.01.08-01.27.54:546][  0]LogConfig: Set CVar [[r.HeterogeneousVolumes.UseExistenceMask:0]]
[2026.01.08-01.27.54:550][  0]LogConfig: Applying CVar settings from Section [FoliageQuality@3] File [Scalability]
[2026.01.08-01.27.54:555][  0]LogConfig: Set CVar [[foliage.DensityScale:1.0]]
[2026.01.08-01.27.54:559][  0]LogConfig: Set CVar [[grass.DensityScale:1.0]]
[2026.01.08-01.27.54:564][  0]LogConfig: Applying CVar settings from Section [ShadingQuality@3] File [Scalability]
[2026.01.08-01.27.54:568][  0]LogConfig: Set CVar [[r.HairStrands.SkyLighting.IntegrationType:2]]
[2026.01.08-01.27.54:573][  0]LogConfig: Set CVar [[r.HairStrands.SkyAO.SampleCount:4]]
[2026.01.08-01.27.54:578][  0]LogConfig: Set CVar [[r.HairStrands.Visibility.MSAA.SamplePerPixel:4]]
[2026.01.08-01.27.54:582][  0]LogConfig: Set CVar [[r.AnisotropicMaterials:1]]
[2026.01.08-01.27.54:590][  0]LogConfig: Applying CVar settings from Section [LandscapeQuality@3] File [Scalability]
[2026.01.08-01.27.54:595][  0]LogInit: Selected Device Profile: [Windows]
[2026.01.08-01.27.54:602][  0]LogHAL: Display: Platform has ~ 64 GB [68642168832 / 68719476736 / 64], which maps to Largest [LargestMinGB=32, LargerMinGB=12, DefaultMinGB=8, SmallerMinGB=6, SmallestMinGB=0)
[2026.01.08-01.27.54:606][  0]LogDeviceProfileManager: Going up to parent DeviceProfile []
[2026.01.08-01.27.54:611][  0]LogDeviceProfileManager: Pushing Device Profile CVar: [[UI.SlateSDFText.RasterizationMode:Bitmap -> Msdf]]
[2026.01.08-01.27.54:615][  0]LogDeviceProfileManager: Pushing Device Profile CVar: [[UI.SlateSDFText.ResolutionLevel:2 -> 2]]
[2026.01.08-01.27.54:620][  0]LogConfig: Applying CVar settings from Section [Startup] File [../../../Engine/Config/ConsoleVariables.ini]
[2026.01.08-01.27.54:624][  0]LogConfig: Set CVar [[r.DumpShaderDebugInfo:2]]
[2026.01.08-01.27.54:627][  0]LogConfig: Set CVar [[p.chaos.AllowCreatePhysxBodies:1]]
[2026.01.08-01.27.54:632][  0]LogConfig: Set CVar [[fx.SkipVectorVMBackendOptimizations:1]]
[2026.01.08-01.27.54:636][  0]LogConfig: CVar [[ds.CADTranslator.Meshing.ActivateThinZoneMeshing:0]] deferred - dummy variable created
[2026.01.08-01.27.54:641][  0]LogConfig: CVar [[ds.CADTranslator.Stitching.RemoveThinFaces:0]] deferred - dummy variable created
[2026.01.08-01.27.54:645][  0]LogConfig: Applying CVar settings from Section [Startup_Windows] File [../../../Engine/Config/ConsoleVariables.ini]
[2026.01.08-01.27.54:652][  0]LogConfig: Applying CVar settings from Section [ConsoleVariables] File [Engine]
[2026.01.08-01.27.54:656][  0]LogInit: Computer: FILFREIRE02
[2026.01.08-01.27.54:660][  0]LogInit: User: filipe
[2026.01.08-01.27.54:665][  0]LogInit: CPU Page size=4096, Cores=12
[2026.01.08-01.27.54:669][  0]LogInit: High frequency timer resolution =10.000000 MHz
[2026.01.08-01.27.54:674][  0]LogMemory: Process is running as part of a Windows Job with separate resource limits
[2026.01.08-01.27.54:678][  0]LogMemory: Memory total: Physical=63.9GB (64GB approx) Virtual=67.9GB
[2026.01.08-01.27.54:683][  0]LogMemory: Platform Memory Stats for Windows
[2026.01.08-01.27.54:686][  0]LogMemory: Process Physical Memory: 148.30 MB used, 148.30 MB peak
[2026.01.08-01.27.54:691][  0]LogMemory: Process Virtual Memory: 101.68 MB used, 101.68 MB peak
[2026.01.08-01.27.54:695][  0]LogMemory: Physical Memory: 12069.16 MB used,  53393.11 MB free, 65462.27 MB total
[2026.01.08-01.27.54:700][  0]LogMemory: Virtual Memory: 16731.23 MB used,  52827.04 MB free, 69558.27 MB total
[2026.01.08-01.27.54:704][  0]LogCsvProfiler: Display: Metadata set : extradevelopmentmemorymb="0"
[2026.01.08-01.27.54:712][  0]LogWindows: WindowsPlatformFeatures enabled
[2026.01.08-01.27.54:717][  0]LogChaosDD: Chaos Debug Draw Startup
[2026.01.08-01.27.54:721][  0]LogInit: Physics initialised using underlying interface: Chaos
[2026.01.08-01.27.54:726][  0]LogInit: Using OS detected language (en-US).
[2026.01.08-01.27.54:731][  0]LogInit: Using OS detected locale (en-US).
[2026.01.08-01.27.54:735][  0]LogTextLocalizationManager: No specific localization for 'en-US' exists, so 'en' will be used for the language.
[2026.01.08-01.27.54:787][  0]LogWindowsTextInputMethodSystem: Available input methods:
[2026.01.08-01.27.54:793][  0]LogWindowsTextInputMethodSystem:   - English (United States) - (Keyboard).
[2026.01.08-01.27.54:797][  0]LogWindowsTextInputMethodSystem:   - Portuguese (Portugal) - (Keyboard).
[2026.01.08-01.27.54:802][  0]LogWindowsTextInputMethodSystem: Activated input method: English (United States) - (Keyboard).
[2026.01.08-01.27.54:834][  0]LogWindowsTouchpad: Display: CacheForceMaxTouchpadSensitivityMode SetTouchpadParameters
[2026.01.08-01.27.54:838][  0]LogObj: Display: Attempting to load config data for Default__SlateThemeManager before the Class has been constructed/registered/linked (likely during module loading or early startup). This will result in the load silently failing and should be fixed.
[2026.01.08-01.27.54:844][  0]LogSlate: New Slate User Created. Platform User Id 0, User Index 0, Is Virtual User: 0
[2026.01.08-01.27.54:849][  0]LogSlate: Slate User Registered.  User Index 0, Is Virtual User: 0
[2026.01.08-01.27.54:910][  0]LogVRS: Current RHI does not support Variable Rate Shading
[2026.01.08-01.27.54:914][  0]LogCsvProfiler: Display: Metadata set : verbatimrhiname="Null"
[2026.01.08-01.27.54:919][  0]LogCsvProfiler: Display: Metadata set : rhiname="Null"
[2026.01.08-01.27.54:926][  0]LogCsvProfiler: Display: Metadata set : rhifeaturelevel="SM6"
[2026.01.08-01.27.54:931][  0]LogCsvProfiler: Display: Metadata set : shaderplatform="PCD3D_SM6"
[2026.01.08-01.27.54:936][  0]LogInit: Initializing FReadOnlyCVARCache
[2026.01.08-01.27.54:946][  0]LogRendererCore: Ray tracing is disabled. Reason: disabled through project setting (r.RayTracing=0).
[2026.01.08-01.27.54:949][  0]LogSlate: Using FreeType 2.10.0
[2026.01.08-01.27.54:951][  0]LogSlate: SlateFontServices - WITH_FREETYPE: 1, WITH_HARFBUZZ: 1
[2026.01.08-01.27.54:962][  0]LogInit: Using OS detected language (en-US).
[2026.01.08-01.27.54:964][  0]LogInit: Using OS detected locale (en-US).
[2026.01.08-01.27.54:970][  0]LogTextLocalizationManager: No localization for 'en-US' exists, so 'en' will be used for the language.
[2026.01.08-01.27.54:975][  0]LogTextLocalizationManager: No localization for 'en-US' exists, so 'en' will be used for the locale.
[2026.01.08-01.27.54:978][  0]LogSlate: FontCache flush requested. Reason: Culture for localization was changed
[2026.01.08-01.27.54:981][  0]LogAssetRegistry: Premade AssetRegistry loaded from '../../../CoopGameFleep/AssetRegistry.bin'
[2026.01.08-01.27.54:984][  0]LogAssetRegistry: FAssetRegistry took 0.0040 seconds to start up
[2026.01.08-01.27.55:105][  0]LogStreaming: Display: FlushAsyncLoading(1): 1 QueuedPackages, 0 AsyncPackages
[2026.01.08-01.27.55:107][  0]LogFilePackageStore: Updated: NewPackages=529, OldPackages=0, TotalPackages=530
[2026.01.08-01.27.55:118][  0]LogDeviceProfileManager: Display: Deviceprofile LinuxArm64Editor not found.
[2026.01.08-01.27.55:120][  0]LogDeviceProfileManager: Display: Deviceprofile LinuxArm64 not found.
[2026.01.08-01.27.55:126][  0]LogDeviceProfileManager: Active device profile: [00007FF3EA26A558][000002381176B6E0 66] Windows
[2026.01.08-01.27.55:128][  0]LogCsvProfiler: Display: Metadata set : deviceprofile="Windows"
[2026.01.08-01.27.55:188][  0]LogTemp: SCharacterManager: RandomSeed set from command line: 1801914551
[2026.01.08-01.27.55:190][  0]LogTemp: SCharacterManager: LearningRatePolicy set from command line: 0.000300
[2026.01.08-01.27.55:197][  0]LogTemp: SCharacterManager: LearningRateCritic set from command line: 0.003000
[2026.01.08-01.27.55:201][  0]LogTemp: SCharacterManager: EpsilonClip set from command line: 0.300000
[2026.01.08-01.27.55:206][  0]LogTemp: SCharacterManager: PolicyBatchSize set from command line: 2048
[2026.01.08-01.27.55:206][  0]LogTemp: SCharacterManager: CriticBatchSize set from command line: 8192
[2026.01.08-01.27.55:208][  0]LogTemp: SCharacterManager: IterationsPerGather set from command line: 64
[2026.01.08-01.27.55:208][  0]LogTemp: SCharacterManager: NumberOfIterations set from command line: 1000000
[2026.01.08-01.27.55:210][  0]LogTemp: SCharacterManager: DiscountFactor set from command line: 0.995000
[2026.01.08-01.27.55:211][  0]LogTemp: SCharacterManager: GaeLambda set from command line: 0.950000
[2026.01.08-01.27.55:212][  0]LogTemp: SCharacterManager: ActionEntropyWeight set from command line: 0.000000
[2026.01.08-01.27.55:213][  0]LogTemp: SCharacterManager: Headless training detected, forcing RunMode to ReInitialize: 2
[2026.01.08-01.27.55:214][  0]LogTemp: SCharacterManager: 1Trainer TaskName set to 'Aggressive-seed-1801914551-750b6e4caaa0'
[2026.01.08-01.27.55:215][  0]LogTemp: SCharacterManager: Configured trainer paths for hostname 'FILFREIRE02':
[2026.01.08-01.27.55:216][  0]LogTemp:   Engine Path: D:/unreal/UE_5.6/Engine
[2026.01.08-01.27.55:217][  0]LogTemp:   Intermediate Path: ../../../../../Intermediate
[2026.01.08-01.27.55:219][  0]LogTemp:   Task Name: Aggressive-seed-1801914551-750b6e4caaa0
[2026.01.08-01.27.55:225][  0]LogAudioCaptureCore: Display: No Audio Capture implementations found. Audio input will be silent.
[2026.01.08-01.27.55:229][  0]LogPackageLocalizationCache: Processed 56 localized package path(s) for 1 prioritized culture(s) in 0.000089 seconds
[2026.01.08-01.27.55:232][  0]LogStats: UGameplayTagsManager::InitializeManager -  0.000 s
[2026.01.08-01.27.55:235][  0]LogConfig: Applying CVar settings from Section [/Script/NNEDenoiser.NNEDenoiserSettings] File [Engine]
[2026.01.08-01.27.55:238][  0]LogAudioCaptureCore: Display: No Audio Capture implementations found. Audio input will be silent.
[2026.01.08-01.27.55:242][  0]LogIris: FNetObjectFactoryRegistry::UnregisterFactory is unregistering factory: NetActorFactory name: NetActorFactory id: 0
[2026.01.08-01.27.55:243][  0]LogIris: FNetObjectFactoryRegistry::UnregisterFactory is unregistering factory: NetSubObjectFactory name: NetSubObjectFactory id: 1
[2026.01.08-01.27.55:246][  0]LogInit: WinSock: version 1.1 (2.2), MaxSocks=32767, MaxUdp=65467
[2026.01.08-01.27.55:251][  0]LogNiagaraDebuggerClient: Niagara Debugger Client Initialized | Session: 18A27009B4C84C99800000000000AC00 | Instance: 1C9D23B544BCD9731A7E0E9B3F60D25F (FILFREIRE02-18988).
[2026.01.08-01.27.55:388][  0]LogNNERuntimeORT: Available graphics and compute adapters:
[2026.01.08-01.27.55:391][  0]LogNNERuntimeORT: No NPU adapter found with attribute DXCORE_ADAPTER_ATTRIBUTE_D3D12_GENERIC_ML (Windows 11 Version 24H2 or newer)!
[2026.01.08-01.27.55:394][  0]LogNNERuntimeORT: Available graphics and compute adapters:
[2026.01.08-01.27.55:398][  0]LogNNERuntimeORT: 0: AMD Radeon RX 6650 XT (Compute, Graphics)
[2026.01.08-01.27.55:401][  0]LogNNERuntimeORT: 1: Microsoft Basic Render Driver (Compute, Graphics)
[2026.01.08-01.27.55:405][  0]LogNNERuntimeORT: No NPU adapter found!
[2026.01.08-01.27.55:407][  0]LogNNERuntimeORT: MakeRuntimeORTDml:
[2026.01.08-01.27.55:411][  0]LogNNERuntimeORT:   DirectML:  yes
[2026.01.08-01.27.55:414][  0]LogNNERuntimeORT:   RHI D3D12: no
[2026.01.08-01.27.55:419][  0]LogNNERuntimeORT:   D3D12:     yes
[2026.01.08-01.27.55:423][  0]LogNNERuntimeORT:   NPU:       no
[2026.01.08-01.27.55:427][  0]LogNNERuntimeORT: Interface availability:
[2026.01.08-01.27.55:430][  0]LogNNERuntimeORT:   GPU: yes
[2026.01.08-01.27.55:435][  0]LogNNERuntimeORT:   RDG: no
[2026.01.08-01.27.55:439][  0]LogNNERuntimeORT:   NPU: no
[2026.01.08-01.27.55:567][  0]LogNNERuntimeORT: Available graphics and compute adapters:
[2026.01.08-01.27.55:569][  0]LogNNERuntimeORT: No NPU adapter found with attribute DXCORE_ADAPTER_ATTRIBUTE_D3D12_GENERIC_ML (Windows 11 Version 24H2 or newer)!
[2026.01.08-01.27.55:571][  0]LogNNERuntimeORT: Available graphics and compute adapters:
[2026.01.08-01.27.55:573][  0]LogNNERuntimeORT: 0: AMD Radeon RX 6650 XT (Compute, Graphics)
[2026.01.08-01.27.55:575][  0]LogNNERuntimeORT: 1: Microsoft Basic Render Driver (Compute, Graphics)
[2026.01.08-01.27.55:577][  0]LogNNERuntimeORT: No NPU adapter found!
[2026.01.08-01.27.55:587][  0]LogUObjectArray: 26912 objects as part of root set at end of initial load.
[2026.01.08-01.27.55:589][  0]LogUObjectArray: 4 objects are not in the root set, but can never be destroyed because they are in the DisregardForGC set.
[2026.01.08-01.27.55:590][  0]LogUObjectArray: CloseDisregardForGC: 26912/26912 objects in disregard for GC pool
[2026.01.08-01.27.55:600][  0]LogEngine: Initializing Engine...
[2026.01.08-01.27.55:605][  0]LogNetVersion: Set ProjectVersion to 1.0.0.0. Version Checksum will be recalculated on next use.
[2026.01.08-01.27.55:607][  0]LogInit: Texture streaming: Disabled
[2026.01.08-01.27.55:610][  0]LogCsvProfiler: Display: Metadata set : largeworldcoordinates="1"
[2026.01.08-01.27.55:613][  0]LogChaosDD: Creating Chaos Debug Draw Scene for world Untitled
[2026.01.08-01.27.55:615][  0]LogNiagara: UAV Float16 is not supported, compressed GPU emitters will be disabled.
[2026.01.08-01.27.55:619][  0]LogEngine: GameWindow did not exist.  Was created
[2026.01.08-01.27.55:621][  0]LogSlate: Updating window title bar state: overlay mode, drag disabled, window buttons hidden, title bar hidden
[2026.01.08-01.27.55:623][  0]LogInit: Display: Game Engine Initialized.
[2026.01.08-01.27.55:625][  0]LogNNEDenoiser: Ray Tracing is not enabled, therefore NNEDenoiser is not registered!
[2026.01.08-01.27.55:633][  0]LogInit: Display: Starting Game.
[2026.01.08-01.27.55:635][  0]LogGlobalStatus: UEngine::Browse Started Browse: "/Game/Maps/P_LearningAgentsTrial1?Name=Player"
[2026.01.08-01.27.55:639][  0]LogNet: Browse: /Game/Maps/P_LearningAgentsTrial1?Name=Player
[2026.01.08-01.27.55:643][  0]LogLoad: LoadMap: /Game/Maps/P_LearningAgentsTrial1?Name=Player
[2026.01.08-01.27.55:647][  0]LogWorld: BeginTearingDown for /Temp/Untitled_0
[2026.01.08-01.27.55:650][  0]LogWorld: UWorld::CleanupWorld for Untitled, bSessionEnded=true, bCleanupResources=true
[2026.01.08-01.27.55:655][  0]LogSlate: InvalidateAllWidgets triggered.  All widgets were invalidated
[2026.01.08-01.27.55:665][  0]LogUObjectHash: Compacting FUObjectHashTables data took   0.86ms
[2026.01.08-01.27.55:694][  0]LogTemp: SCharacterManager: RandomSeed set from command line: 1801914551
[2026.01.08-01.27.55:697][  0]LogTemp: SCharacterManager: LearningRatePolicy set from command line: 0.000300
[2026.01.08-01.27.55:699][  0]LogTemp: SCharacterManager: LearningRateCritic set from command line: 0.003000
[2026.01.08-01.27.55:702][  0]LogTemp: SCharacterManager: EpsilonClip set from command line: 0.300000
[2026.01.08-01.27.55:705][  0]LogTemp: SCharacterManager: PolicyBatchSize set from command line: 2048
[2026.01.08-01.27.55:707][  0]LogTemp: SCharacterManager: CriticBatchSize set from command line: 8192
[2026.01.08-01.27.55:708][  0]LogTemp: SCharacterManager: IterationsPerGather set from command line: 64
[2026.01.08-01.27.55:711][  0]LogTemp: SCharacterManager: NumberOfIterations set from command line: 1000000
[2026.01.08-01.27.55:711][  0]LogTemp: SCharacterManager: DiscountFactor set from command line: 0.995000
[2026.01.08-01.27.55:713][  0]LogTemp: SCharacterManager: GaeLambda set from command line: 0.950000
[2026.01.08-01.27.55:715][  0]LogTemp: SCharacterManager: ActionEntropyWeight set from command line: 0.000000
[2026.01.08-01.27.55:718][  0]LogTemp: SCharacterManager: Headless training detected, forcing RunMode to ReInitialize: 2
[2026.01.08-01.27.55:719][  0]LogTemp: SCharacterManager: 1Trainer TaskName set to 'Aggressive-seed-1801914551-750b6e4caaa0'
[2026.01.08-01.27.55:720][  0]LogTemp: SCharacterManager: Configured trainer paths for hostname 'FILFREIRE02':
[2026.01.08-01.27.55:721][  0]LogTemp:   Engine Path: D:/unreal/UE_5.6/Engine
[2026.01.08-01.27.55:723][  0]LogTemp:   Intermediate Path: ../../../../../Intermediate
[2026.01.08-01.27.55:723][  0]LogTemp:   Task Name: Aggressive-seed-1801914551-750b6e4caaa0
[2026.01.08-01.27.55:725][  0]LogTemp: SCharacterManager: RandomSeed set from command line: 1801914551
[2026.01.08-01.27.55:725][  0]LogTemp: SCharacterManager: LearningRatePolicy set from command line: 0.000300
[2026.01.08-01.27.55:727][  0]LogTemp: SCharacterManager: LearningRateCritic set from command line: 0.003000
[2026.01.08-01.27.55:727][  0]LogTemp: SCharacterManager: EpsilonClip set from command line: 0.300000
[2026.01.08-01.27.55:729][  0]LogTemp: SCharacterManager: PolicyBatchSize set from command line: 2048
[2026.01.08-01.27.55:731][  0]LogTemp: SCharacterManager: CriticBatchSize set from command line: 8192
[2026.01.08-01.27.55:734][  0]LogTemp: SCharacterManager: IterationsPerGather set from command line: 64
[2026.01.08-01.27.55:735][  0]LogTemp: SCharacterManager: NumberOfIterations set from command line: 1000000
[2026.01.08-01.27.55:737][  0]LogTemp: SCharacterManager: DiscountFactor set from command line: 0.995000
[2026.01.08-01.27.55:739][  0]LogTemp: SCharacterManager: GaeLambda set from command line: 0.950000
[2026.01.08-01.27.55:741][  0]LogTemp: SCharacterManager: ActionEntropyWeight set from command line: 0.000000
[2026.01.08-01.27.55:743][  0]LogTemp: SCharacterManager: Headless training detected, forcing RunMode to ReInitialize: 2
[2026.01.08-01.27.55:745][  0]LogTemp: SCharacterManager: 1Trainer TaskName set to 'Aggressive-seed-1801914551-750b6e4caaa0'
[2026.01.08-01.27.55:747][  0]LogTemp: SCharacterManager: Configured trainer paths for hostname 'FILFREIRE02':
[2026.01.08-01.27.55:752][  0]LogTemp:   Engine Path: D:/unreal/UE_5.6/Engine
[2026.01.08-01.27.55:754][  0]LogTemp:   Intermediate Path: ../../../../../Intermediate
[2026.01.08-01.27.55:755][  0]LogTemp:   Task Name: Aggressive-seed-1801914551-750b6e4caaa0
[2026.01.08-01.27.55:760][  0]LogChaosDD: Creating Chaos Debug Draw Scene for world P_LearningAgentsTrial1
[2026.01.08-01.27.55:765][  0]LogLoad: Game class is 'GameModeBase'
[2026.01.08-01.27.55:771][  0]LogWorld: Bringing World /Game/Maps/P_LearningAgentsTrial1.P_LearningAgentsTrial1 up for play (max tick rate 0) at 2026.01.08-01.27.55
[2026.01.08-01.27.55:774][  0]LogWorld: Bringing up level for play took: 0.007535
[2026.01.08-01.27.55:778][  0]LogGameMode: FindPlayerStart: PATHS NOT DEFINED or NO PLAYERSTART with positive rating
[2026.01.08-01.27.55:783][  0]LogTemp: Warning: SCharacterManager: Found 8 total characters in world
[2026.01.08-01.27.55:785][  0]LogTemp: Warning: SCharacterManager: Found 8 SCharacter agents
[2026.01.08-01.27.55:788][  0]LogTemp: Warning: Character 0: PlayerPawn_0 (Class: PlayerPawn_C) - SCharacter Cast: SUCCESS
[2026.01.08-01.27.55:790][  0]LogTemp: Warning: Character 1: PlayerPawn_1 (Class: PlayerPawn_C) - SCharacter Cast: SUCCESS
[2026.01.08-01.27.55:794][  0]LogTemp: Warning: Character 2: PlayerPawn_2 (Class: PlayerPawn_C) - SCharacter Cast: SUCCESS
[2026.01.08-01.27.55:797][  0]LogTemp: Warning: Character 3: PlayerPawn_3 (Class: PlayerPawn_C) - SCharacter Cast: SUCCESS
[2026.01.08-01.27.55:800][  0]LogTemp: Warning: Character 4: PlayerPawn_4 (Class: PlayerPawn_C) - SCharacter Cast: SUCCESS
[2026.01.08-01.27.55:803][  0]LogTemp: Warning: Character 5: PlayerPawn_5 (Class: PlayerPawn_C) - SCharacter Cast: SUCCESS
[2026.01.08-01.27.55:808][  0]LogTemp: Warning: Character 6: PlayerPawn_6 (Class: PlayerPawn_C) - SCharacter Cast: SUCCESS
[2026.01.08-01.27.55:813][  0]LogTemp: Warning: Character 7: PlayerPawn_7 (Class: PlayerPawn_C) - SCharacter Cast: SUCCESS
[2026.01.08-01.27.55:816][  0]LogTemp: Warning: SCharacterManager: Created AIController for agent PlayerPawn_0
[2026.01.08-01.27.55:819][  0]LogLearning: Display: Learning Agents Manager: Adding Agent PlayerPawn_0 with id 0.
[2026.01.08-01.27.55:823][  0]LogTemp: Warning: SCharacterManager: Added agent PlayerPawn_0 to manager with ID 0
[2026.01.08-01.27.55:829][  0]LogTemp: Health reset to: 100.0
[2026.01.08-01.27.55:832][  0]LogTemp: SCharacterManager: Initialized PlayerPawn_0 for learning
[2026.01.08-01.27.55:837][  0]LogTemp: Warning: SCharacterManager: Created AIController for agent PlayerPawn_1
[2026.01.08-01.27.55:841][  0]LogLearning: Display: Learning Agents Manager: Adding Agent PlayerPawn_1 with id 1.
[2026.01.08-01.27.55:844][  0]LogTemp: Warning: SCharacterManager: Added agent PlayerPawn_1 to manager with ID 1
[2026.01.08-01.27.55:846][  0]LogTemp: Health reset to: 100.0
[2026.01.08-01.27.55:849][  0]LogTemp: SCharacterManager: Initialized PlayerPawn_1 for learning
[2026.01.08-01.27.55:853][  0]LogTemp: Warning: SCharacterManager: Created AIController for agent PlayerPawn_2
[2026.01.08-01.27.55:857][  0]LogLearning: Display: Learning Agents Manager: Adding Agent PlayerPawn_2 with id 2.
[2026.01.08-01.27.55:861][  0]LogTemp: Warning: SCharacterManager: Added agent PlayerPawn_2 to manager with ID 2
[2026.01.08-01.27.55:864][  0]LogTemp: Health reset to: 100.0
[2026.01.08-01.27.55:869][  0]LogTemp: SCharacterManager: Initialized PlayerPawn_2 for learning
[2026.01.08-01.27.55:873][  0]LogTemp: Warning: SCharacterManager: Created AIController for agent PlayerPawn_3
[2026.01.08-01.27.55:878][  0]LogLearning: Display: Learning Agents Manager: Adding Agent PlayerPawn_3 with id 3.
[2026.01.08-01.27.55:883][  0]LogTemp: Warning: SCharacterManager: Added agent PlayerPawn_3 to manager with ID 3
[2026.01.08-01.27.55:887][  0]LogTemp: Health reset to: 100.0
[2026.01.08-01.27.55:892][  0]LogTemp: SCharacterManager: Initialized PlayerPawn_3 for learning
[2026.01.08-01.27.55:897][  0]LogTemp: Warning: SCharacterManager: Created AIController for agent PlayerPawn_4
[2026.01.08-01.27.55:901][  0]LogLearning: Display: Learning Agents Manager: Adding Agent PlayerPawn_4 with id 4.
[2026.01.08-01.27.55:904][  0]LogTemp: Warning: SCharacterManager: Added agent PlayerPawn_4 to manager with ID 4
[2026.01.08-01.27.55:910][  0]LogTemp: Health reset to: 100.0
[2026.01.08-01.27.55:914][  0]LogTemp: SCharacterManager: Initialized PlayerPawn_4 for learning
[2026.01.08-01.27.55:918][  0]LogTemp: Warning: SCharacterManager: Created AIController for agent PlayerPawn_5
[2026.01.08-01.27.55:922][  0]LogLearning: Display: Learning Agents Manager: Adding Agent PlayerPawn_5 with id 5.
[2026.01.08-01.27.55:927][  0]LogTemp: Warning: SCharacterManager: Added agent PlayerPawn_5 to manager with ID 5
[2026.01.08-01.27.55:933][  0]LogTemp: Health reset to: 100.0
[2026.01.08-01.27.55:937][  0]LogTemp: SCharacterManager: Initialized PlayerPawn_5 for learning
[2026.01.08-01.27.55:941][  0]LogTemp: Warning: SCharacterManager: Created AIController for agent PlayerPawn_6
[2026.01.08-01.27.55:946][  0]LogLearning: Display: Learning Agents Manager: Adding Agent PlayerPawn_6 with id 6.
[2026.01.08-01.27.55:951][  0]LogTemp: Warning: SCharacterManager: Added agent PlayerPawn_6 to manager with ID 6
[2026.01.08-01.27.55:959][  0]LogTemp: Health reset to: 100.0
[2026.01.08-01.27.55:962][  0]LogTemp: SCharacterManager: Initialized PlayerPawn_6 for learning
[2026.01.08-01.27.55:969][  0]LogTemp: SCharacterManager: Agent PlayerPawn_7 already has controller PlayerController
[2026.01.08-01.27.55:973][  0]LogLearning: Display: Learning Agents Manager: Adding Agent PlayerPawn_7 with id 7.
[2026.01.08-01.27.55:976][  0]LogTemp: Warning: SCharacterManager: Added agent PlayerPawn_7 to manager with ID 7
[2026.01.08-01.27.55:980][  0]LogTemp: Health reset to: 100.0
[2026.01.08-01.27.55:983][  0]LogTemp: SCharacterManager: Initialized PlayerPawn_7 for learning
[2026.01.08-01.27.55:986][  0]LogTemp: SCharacterManager: Initialized 8 character agents
[2026.01.08-01.27.55:990][  0]LogTemp: SCharacterManager: InitializeManager called with RunMode: 2
[2026.01.08-01.27.56:000][  0]LogLearning: Warning: GetCustomTrainerModulePath: NonEditorCustomTrainerModulePath not set
[2026.01.08-01.27.56:009][  0]LogTemp: SCharacterManager: Initialization complete. Mode: 2
[2026.01.08-01.27.56:015][  0]LogLoad: Took 0.371842 seconds to LoadMap(/Game/Maps/P_LearningAgentsTrial1)
[2026.01.08-01.27.56:018][  0]LogGlobalStatus: UEngine::LoadMap Load map complete /Game/Maps/P_LearningAgentsTrial1
[2026.01.08-01.27.56:023][  0]LogPakFile: AllPaks IndexSizes: DirectoryHashSize=32, PathHashSize=16, EntriesSize=32752, DirTreeIndexSize=163760, TotalSize=196560
[2026.01.08-01.27.56:051][  0]LogInit: Display: Engine is initialized. Leaving FEngineLoop::Init()
[2026.01.08-01.27.56:055][  0]LogLoad: (Engine Initialization) Total time: 4.00 seconds
[2026.01.08-01.27.56:078][  0]LogTrace: Display: Control listening on port 1985
[2026.01.08-01.27.56:094][  1]LogLearning: Display: SCharacter PPO Trainer_0: Sending configs...
[2026.01.08-01.27.56:103][  1]LogLearning: Display: Wrote Config Files to ../../../../../Intermediate/LearningAgents/Aggressive-seed-1801914551-750b6e4caaa00/Configs. Sending Config Signal...
[2026.01.08-01.27.56:107][  1]LogLearning: Display: Sending config signal...
[2026.01.08-01.27.56:112][  1]LogLearning: Display: SCharacter PPO Trainer_0: Sending initial policy...
[2026.01.08-01.27.58:331][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {9706CF70-4C5F-5524-94EF-9A8661ADF4EE}
[2026.01.08-01.27.58:415][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {8236CC17-4560-6DF7-07F6-53A6392D6D66}
[2026.01.08-01.27.58:440][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {874066FE-42DE-C92D-7136-9EAB793A231D}
[2026.01.08-01.27.58:463][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {1639E8B5-477D-02A7-DC54-EDABDA069DE0}
[2026.01.08-01.27.58:475][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {C7FEF938-46A5-2F56-3055-8C90E0DB7709}
[2026.01.08-01.27.58:522][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {D52D0319-4DA9-2B4A-5BAE-B9B42DB20B82}
[2026.01.08-01.27.58:526][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {C1CBFDE2-4FCA-03D1-F82B-31811F26EA49}
[2026.01.08-01.27.58:528][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {62044207-4E7C-FF4A-A7D2-2C9FFBCE93D1}
[2026.01.08-01.27.58:531][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {A4FDB1B1-4B60-B935-187C-77BB2D4B88C8}
[2026.01.08-01.27.58:533][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {4E6613AB-4222-8751-904A-B6B132277C96}
[2026.01.08-01.27.58:536][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {1CBB09F2-4D4B-6DCC-B98C-AF8CBE21752D}
[2026.01.08-01.27.58:540][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {1437C955-4770-4123-BBD5-E3A686E17742}
[2026.01.08-01.27.58:541][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {118BA6F0-4A2B-50ED-12F6-8D8669EB37C2}
[2026.01.08-01.27.58:544][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {0B982C55-4D63-25FC-D549-C38076958CB0}
[2026.01.08-01.27.58:560][  1]LogLearning: Display: Subprocess: INFO: Mapped existing shared memory with name: {9005913F-4F05-C49C-8F04-098C53CFAA1B}
[2026.01.08-01.27.58:562][  1]LogLearning: Display: Subprocess: INFO: {
[2026.01.08-01.27.58:565][  1]LogLearning: Display: Subprocess:     "SharedMemory": {
[2026.01.08-01.27.58:567][  1]LogLearning: Display: Subprocess:         "NetworkGuids": [
[2026.01.08-01.27.58:569][  1]LogLearning: Display: Subprocess:             {
[2026.01.08-01.27.58:581][  1]LogLearning: Display: Subprocess:                 "NetworkId": 0,
[2026.01.08-01.27.58:583][  1]LogLearning: Display: Subprocess:                 "Guid": "{8236CC17-4560-6DF7-07F6-53A6392D6D66}"
[2026.01.08-01.27.58:586][  1]LogLearning: Display: Subprocess:             },
[2026.01.08-01.27.58:588][  1]LogLearning: Display: Subprocess:             {
[2026.01.08-01.27.58:591][  1]LogLearning: Display: Subprocess:                 "NetworkId": 1,
[2026.01.08-01.27.58:593][  1]LogLearning: Display: Subprocess:                 "Guid": "{874066FE-42DE-C92D-7136-9EAB793A231D}"
[2026.01.08-01.27.58:597][  1]LogLearning: Display: Subprocess:             },
[2026.01.08-01.27.58:599][  1]LogLearning: Display: Subprocess:             {
[2026.01.08-01.27.58:602][  1]LogLearning: Display: Subprocess:                 "NetworkId": 2,
[2026.01.08-01.27.58:613][  1]LogLearning: Display: Subprocess:                 "Guid": "{1639E8B5-477D-02A7-DC54-EDABDA069DE0}"
[2026.01.08-01.27.58:616][  1]LogLearning: Display: Subprocess:             },
[2026.01.08-01.27.58:620][  1]LogLearning: Display: Subprocess:             {
[2026.01.08-01.27.58:623][  1]LogLearning: Display: Subprocess:                 "NetworkId": 3,
[2026.01.08-01.27.58:627][  1]LogLearning: Display: Subprocess:                 "Guid": "{C7FEF938-46A5-2F56-3055-8C90E0DB7709}"
[2026.01.08-01.27.58:630][  1]LogLearning: Display: Subprocess:             }
[2026.01.08-01.27.58:634][  1]LogLearning: Display: Subprocess:         ],
[2026.01.08-01.27.58:636][  1]LogLearning: Display: Subprocess:         "ReplayBuffers": [
[2026.01.08-01.27.58:646][  1]LogLearning: Display: Subprocess:             {
[2026.01.08-01.27.58:648][  1]LogLearning: Display: Subprocess:                 "EpisodeStartsGuid": "{D52D0319-4DA9-2B4A-5BAE-B9B42DB20B82}",
[2026.01.08-01.27.58:651][  1]LogLearning: Display: Subprocess:                 "EpisodeLengthsGuid": "{C1CBFDE2-4FCA-03D1-F82B-31811F26EA49}",
[2026.01.08-01.27.58:653][  1]LogLearning: Display: Subprocess:                 "EpisodeCompletionModesGuid": "{62044207-4E7C-FF4A-A7D2-2C9FFBCE93D1}",
[2026.01.08-01.27.58:656][  1]LogLearning: Display: Subprocess:                 "EpisodeFinalObservationsGuids": [
[2026.01.08-01.27.58:658][  1]LogLearning: Display: Subprocess:                     "{A4FDB1B1-4B60-B935-187C-77BB2D4B88C8}"
[2026.01.08-01.27.58:661][  1]LogLearning: Display: Subprocess:                 ],
[2026.01.08-01.27.58:666][  1]LogLearning: Display: Subprocess:                 "EpisodeFinalMemoryStatesGuids": [
[2026.01.08-01.27.58:682][  1]LogLearning: Display: Subprocess:                     "{118BA6F0-4A2B-50ED-12F6-8D8669EB37C2}"
[2026.01.08-01.27.58:685][  1]LogLearning: Display: Subprocess:                 ],
[2026.01.08-01.27.58:688][  1]LogLearning: Display: Subprocess:                 "ObservationsGuids": [
[2026.01.08-01.27.58:691][  1]LogLearning: Display: Subprocess:                     "{4E6613AB-4222-8751-904A-B6B132277C96}"
[2026.01.08-01.27.58:697][  1]LogLearning: Display: Subprocess:                 ],
[2026.01.08-01.27.58:701][  1]LogLearning: Display: Subprocess:                 "ActionsGuids": [
[2026.01.08-01.27.58:715][  1]LogLearning: Display: Subprocess:                     "{1CBB09F2-4D4B-6DCC-B98C-AF8CBE21752D}"
[2026.01.08-01.27.58:721][  1]LogLearning: Display: Subprocess:                 ],
[2026.01.08-01.27.58:726][  1]LogLearning: Display: Subprocess:                 "ActionModifiersGuids": [
[2026.01.08-01.27.58:729][  1]LogLearning: Display: Subprocess:                     "{1437C955-4770-4123-BBD5-E3A686E17742}"
[2026.01.08-01.27.58:732][  1]LogLearning: Display: Subprocess:                 ],
[2026.01.08-01.27.58:748][  1]LogLearning: Display: Subprocess:                 "MemoryStatesGuids": [
[2026.01.08-01.27.58:751][  1]LogLearning: Display: Subprocess:                     "{0B982C55-4D63-25FC-D549-C38076958CB0}"
[2026.01.08-01.27.58:758][  1]LogLearning: Display: Subprocess:                 ],
[2026.01.08-01.27.58:763][  1]LogLearning: Display: Subprocess:                 "RewardsGuids": [
[2026.01.08-01.27.58:767][  1]LogLearning: Display: Subprocess:                     "{9005913F-4F05-C49C-8F04-098C53CFAA1B}"
[2026.01.08-01.27.58:771][  1]LogLearning: Display: Subprocess:                 ]
[2026.01.08-01.27.58:786][  1]LogLearning: Display: Subprocess:             }
[2026.01.08-01.27.58:790][  1]LogLearning: Display: Subprocess:         ]
[2026.01.08-01.27.58:794][  1]LogLearning: Display: Subprocess:     },
[2026.01.08-01.27.58:798][  1]LogLearning: Display: Subprocess:     "Networks": [
[2026.01.08-01.27.58:803][  1]LogLearning: Display: Subprocess:         {
[2026.01.08-01.27.58:810][  1]LogLearning: Display: Subprocess:             "Id": 0,
[2026.01.08-01.27.58:822][  1]LogLearning: Display: Subprocess:             "Name": "NN_CharacterPolicy",
[2026.01.08-01.27.58:827][  1]LogLearning: Display: Subprocess:             "MaxByteNum": 475192
[2026.01.08-01.27.58:831][  1]LogLearning: Display: Subprocess:         },
[2026.01.08-01.27.58:836][  1]LogLearning: Display: Subprocess:         {
[2026.01.08-01.27.58:843][  1]LogLearning: Display: Subprocess:             "Id": 1,
[2026.01.08-01.27.58:851][  1]LogLearning: Display: Subprocess:             "Name": "NN_CharacterCritic",
[2026.01.08-01.27.58:864][  1]LogLearning: Display: Subprocess:             "MaxByteNum": 108824,
[2026.01.08-01.27.58:870][  1]LogLearning: Display: Subprocess:             "InputSchemaId": 0
[2026.01.08-01.27.58:873][  1]LogLearning: Display: Subprocess:         },
[2026.01.08-01.27.58:878][  1]LogLearning: Display: Subprocess:         {
[2026.01.08-01.27.58:881][  1]LogLearning: Display: Subprocess:             "Id": 2,
[2026.01.08-01.27.58:886][  1]LogLearning: Display: Subprocess:             "Name": "NN_CharacterEncoder",
[2026.01.08-01.27.58:902][  1]LogLearning: Display: Subprocess:             "MaxByteNum": 1060,
[2026.01.08-01.27.58:906][  1]LogLearning: Display: Subprocess:             "InputSchemaId": 0
[2026.01.08-01.27.58:910][  1]LogLearning: Display: Subprocess:         },
[2026.01.08-01.27.58:914][  1]LogLearning: Display: Subprocess:         {
[2026.01.08-01.27.58:918][  1]LogLearning: Display: Subprocess:             "Id": 3,
[2026.01.08-01.27.58:934][  1]LogLearning: Display: Subprocess:             "Name": "NN_CharacterDecoder",
[2026.01.08-01.27.58:937][  1]LogLearning: Display: Subprocess:             "MaxByteNum": 544,
[2026.01.08-01.27.58:942][  1]LogLearning: Display: Subprocess:             "OutputSchemaId": 0
[2026.01.08-01.27.58:945][  1]LogLearning: Display: Subprocess:         }
[2026.01.08-01.27.58:950][  1]LogLearning: Display: Subprocess:     ],
[2026.01.08-01.27.58:955][  1]LogLearning: Display: Subprocess:     "ReplayBuffers": [
[2026.01.08-01.27.58:968][  1]LogLearning: Display: Subprocess:         {
[2026.01.08-01.27.58:972][  1]LogLearning: Display: Subprocess:             "Id": 0,
[2026.01.08-01.27.58:976][  1]LogLearning: Display: Subprocess:             "MaxEpisodeNum": 1000,
[2026.01.08-01.27.58:982][  1]LogLearning: Display: Subprocess:             "MaxStepNum": 10000,
[2026.01.08-01.27.58:985][  1]LogLearning: Display: Subprocess:             "HasCompletions": true,
[2026.01.08-01.27.58:988][  1]LogLearning: Display: Subprocess:             "HasFinalObservations": true,
[2026.01.08-01.27.59:002][  1]LogLearning: Display: Subprocess:             "HasFinalMemoryStates": true,
[2026.01.08-01.27.59:007][  1]LogLearning: Display: Subprocess:             "Observations": [
[2026.01.08-01.27.59:010][  1]LogLearning: Display: Subprocess:                 {
[2026.01.08-01.27.59:015][  1]LogLearning: Display: Subprocess:                     "Id": 0,
[2026.01.08-01.27.59:019][  1]LogLearning: Display: Subprocess:                     "Name": "Observations",
[2026.01.08-01.27.59:023][  1]LogLearning: Display: Subprocess:                     "SchemaId": 0,
[2026.01.08-01.27.59:029][  1]LogLearning: Display: Subprocess:                     "VectorDimensionNum": 17
[2026.01.08-01.27.59:041][  1]LogLearning: Display: Subprocess:                 }
[2026.01.08-01.27.59:045][  1]LogLearning: Display: Subprocess:             ],
[2026.01.08-01.27.59:049][  1]LogLearning: Display: Subprocess:             "Actions": [
[2026.01.08-01.27.59:053][  1]LogLearning: Display: Subprocess:                 {
[2026.01.08-01.27.59:058][  1]LogLearning: Display: Subprocess:                     "Id": 0,
[2026.01.08-01.27.59:064][  1]LogLearning: Display: Subprocess:                     "Name": "Actions",
[2026.01.08-01.27.59:080][  1]LogLearning: Display: Subprocess:                     "SchemaId": 0,
[2026.01.08-01.27.59:083][  1]LogLearning: Display: Subprocess:                     "VectorDimensionNum": 3
[2026.01.08-01.27.59:088][  1]LogLearning: Display: Subprocess:                 }
[2026.01.08-01.27.59:092][  1]LogLearning: Display: Subprocess:             ],
[2026.01.08-01.27.59:098][  1]LogLearning: Display: Subprocess:             "ActionModifiers": [
[2026.01.08-01.27.59:104][  1]LogLearning: Display: Subprocess:                 {
[2026.01.08-01.27.59:116][  1]LogLearning: Display: Subprocess:                     "Id": 0,
[2026.01.08-01.27.59:120][  1]LogLearning: Display: Subprocess:                     "Name": "ActionModifiers",
[2026.01.08-01.27.59:125][  1]LogLearning: Display: Subprocess:                     "SchemaId": 0,
[2026.01.08-01.27.59:129][  1]LogLearning: Display: Subprocess:                     "VectorDimensionNum": 10
[2026.01.08-01.27.59:133][  1]LogLearning: Display: Subprocess:                 }
[2026.01.08-01.27.59:136][  1]LogLearning: Display: Subprocess:             ],
[2026.01.08-01.27.59:156][  1]LogLearning: Display: Subprocess:             "MemoryStates": [
[2026.01.08-01.27.59:161][  1]LogLearning: Display: Subprocess:                 {
[2026.01.08-01.27.59:165][  1]LogLearning: Display: Subprocess:                     "Id": 0,
[2026.01.08-01.27.59:169][  1]LogLearning: Display: Subprocess:                     "Name": "MemoryStates",
[2026.01.08-01.27.59:173][  1]LogLearning: Display: Subprocess:                     "VectorDimensionNum": 64
[2026.01.08-01.27.59:177][  1]LogLearning: Display: Subprocess:                 }
[2026.01.08-01.27.59:193][  1]LogLearning: Display: Subprocess:             ],
[2026.01.08-01.27.59:197][  1]LogLearning: Display: Subprocess:             "Rewards": [
[2026.01.08-01.27.59:201][  1]LogLearning: Display: Subprocess:                 {
[2026.01.08-01.27.59:206][  1]LogLearning: Display: Subprocess:                     "Id": 0,
[2026.01.08-01.27.59:210][  1]LogLearning: Display: Subprocess:                     "Name": "Rewards",
[2026.01.08-01.27.59:214][  1]LogLearning: Display: Subprocess:                     "VectorDimensionNum": 1
[2026.01.08-01.27.59:232][  1]LogLearning: Display: Subprocess:                 }
[2026.01.08-01.27.59:237][  1]LogLearning: Display: Subprocess:             ]
[2026.01.08-01.27.59:242][  1]LogLearning: Display: Subprocess:         }
[2026.01.08-01.27.59:247][  1]LogLearning: Display: Subprocess:     ],
[2026.01.08-01.27.59:251][  1]LogLearning: Display: Subprocess:     "Schemas": {
[2026.01.08-01.27.59:257][  1]LogLearning: Display: Subprocess:         "Observations": [
[2026.01.08-01.27.59:273][  1]LogLearning: Display: Subprocess:             {
[2026.01.08-01.27.59:277][  1]LogLearning: Display: Subprocess:                 "Id": 0,
[2026.01.08-01.27.59:282][  1]LogLearning: Display: Subprocess:                 "Name": "Default",
[2026.01.08-01.27.59:287][  1]LogLearning: Display: Subprocess:                 "Schema": {
[2026.01.08-01.27.59:293][  1]LogLearning: Display: Subprocess:                     "VectorSize": 17,
[2026.01.08-01.27.59:311][  1]LogLearning: Display: Subprocess:                     "EncodedSize": 17,
[2026.01.08-01.27.59:315][  1]LogLearning: Display: Subprocess:                     "Type": "And",
[2026.01.08-01.27.59:319][  1]LogLearning: Display: Subprocess:                     "Elements": {
[2026.01.08-01.27.59:324][  1]LogLearning: Display: Subprocess:                         "CharacterDirection": {
[2026.01.08-01.27.59:327][  1]LogLearning: Display: Subprocess:                             "VectorSize": 3,
[2026.01.08-01.27.59:334][  1]LogLearning: Display: Subprocess:                             "EncodedSize": 3,
[2026.01.08-01.27.59:352][  1]LogLearning: Display: Subprocess:                             "Type": "Continuous",
[2026.01.08-01.27.59:355][  1]LogLearning: Display: Subprocess:                             "Num": 3,
[2026.01.08-01.27.59:359][  1]LogLearning: Display: Subprocess:                             "Index": 0
[2026.01.08-01.27.59:366][  1]LogLearning: Display: Subprocess:                         },
[2026.01.08-01.27.59:370][  1]LogLearning: Display: Subprocess:                         "CharacterLocation": {
[2026.01.08-01.27.59:387][  1]LogLearning: Display: Subprocess:                             "VectorSize": 3,
[2026.01.08-01.27.59:391][  1]LogLearning: Display: Subprocess:                             "EncodedSize": 3,
[2026.01.08-01.27.59:395][  1]LogLearning: Display: Subprocess:                             "Type": "Continuous",
[2026.01.08-01.27.59:399][  1]LogLearning: Display: Subprocess:                             "Num": 3,
[2026.01.08-01.27.59:402][  1]LogLearning: Display: Subprocess:                             "Index": 1
[2026.01.08-01.27.59:407][  1]LogLearning: Display: Subprocess:                         },
[2026.01.08-01.27.59:411][  1]LogLearning: Display: Subprocess:                         "CharacterVelocity": {
[2026.01.08-01.27.59:429][  1]LogLearning: Display: Subprocess:                             "VectorSize": 3,
[2026.01.08-01.27.59:434][  1]LogLearning: Display: Subprocess:                             "EncodedSize": 3,
[2026.01.08-01.27.59:437][  1]LogLearning: Display: Subprocess:                             "Type": "Continuous",
[2026.01.08-01.27.59:441][  1]LogLearning: Display: Subprocess:                             "Num": 3,
[2026.01.08-01.27.59:446][  1]LogLearning: Display: Subprocess:                             "Index": 2
[2026.01.08-01.27.59:464][  1]LogLearning: Display: Subprocess:                         },
[2026.01.08-01.27.59:466][  1]LogLearning: Display: Subprocess:                         "DirectionToTarget": {
[2026.01.08-01.27.59:471][  1]LogLearning: Display: Subprocess:                             "VectorSize": 3,
[2026.01.08-01.27.59:475][  1]LogLearning: Display: Subprocess:                             "EncodedSize": 3,
[2026.01.08-01.27.59:479][  1]LogLearning: Display: Subprocess:                             "Type": "Continuous",
[2026.01.08-01.27.59:483][  1]LogLearning: Display: Subprocess:                             "Num": 3,
[2026.01.08-01.27.59:487][  1]LogLearning: Display: Subprocess:                             "Index": 3
[2026.01.08-01.27.59:504][  1]LogLearning: Display: Subprocess:                         },
[2026.01.08-01.27.59:510][  1]LogLearning: Display: Subprocess:                         "DistanceToTarget": {
[2026.01.08-01.27.59:514][  1]LogLearning: Display: Subprocess:                             "VectorSize": 1,
[2026.01.08-01.27.59:518][  1]LogLearning: Display: Subprocess:                             "EncodedSize": 1,
[2026.01.08-01.27.59:526][  1]LogLearning: Display: Subprocess:                             "Type": "Continuous",
[2026.01.08-01.27.59:531][  1]LogLearning: Display: Subprocess:                             "Num": 1,
[2026.01.08-01.27.59:549][  1]LogLearning: Display: Subprocess:                             "Index": 4
[2026.01.08-01.27.59:554][  1]LogLearning: Display: Subprocess:                         },
[2026.01.08-01.27.59:558][  1]LogLearning: Display: Subprocess:                         "FacingAlignment": {
[2026.01.08-01.27.59:563][  1]LogLearning: Display: Subprocess:                             "VectorSize": 1,
[2026.01.08-01.27.59:566][  1]LogLearning: Display: Subprocess:                             "EncodedSize": 1,
[2026.01.08-01.27.59:571][  1]LogLearning: Display: Subprocess:                             "Type": "Continuous",
[2026.01.08-01.27.59:589][  1]LogLearning: Display: Subprocess:                             "Num": 1,
[2026.01.08-01.27.59:593][  1]LogLearning: Display: Subprocess:                             "Index": 5
[2026.01.08-01.27.59:597][  1]LogLearning: Display: Subprocess:                         },
[2026.01.08-01.27.59:601][  1]LogLearning: Display: Subprocess:                         "TargetLocation": {
[2026.01.08-01.27.59:606][  1]LogLearning: Display: Subprocess:                             "VectorSize": 3,
[2026.01.08-01.27.59:609][  1]LogLearning: Display: Subprocess:                             "EncodedSize": 3,
[2026.01.08-01.27.59:630][  1]LogLearning: Display: Subprocess:                             "Type": "Continuous",
[2026.01.08-01.27.59:634][  1]LogLearning: Display: Subprocess:                             "Num": 3,
[2026.01.08-01.27.59:638][  1]LogLearning: Display: Subprocess:                             "Index": 6
[2026.01.08-01.27.59:642][  1]LogLearning: Display: Subprocess:                         }
[2026.01.08-01.27.59:647][  1]LogLearning: Display: Subprocess:                     }
[2026.01.08-01.27.59:654][  1]LogLearning: Display: Subprocess:                 }
[2026.01.08-01.27.59:669][  1]LogLearning: Display: Subprocess:             }
[2026.01.08-01.27.59:674][  1]LogLearning: Display: Subprocess:         ],
[2026.01.08-01.27.59:677][  1]LogLearning: Display: Subprocess:         "Actions": [
[2026.01.08-01.27.59:682][  1]LogLearning: Display: Subprocess:             {
[2026.01.08-01.27.59:686][  1]LogLearning: Display: Subprocess:                 "Id": 0,
[2026.01.08-01.27.59:689][  1]LogLearning: Display: Subprocess:                 "Name": "Default",
[2026.01.08-01.27.59:705][  1]LogLearning: Display: Subprocess:                 "Schema": {
[2026.01.08-01.27.59:708][  1]LogLearning: Display: Subprocess:                     "VectorSize": 3,
[2026.01.08-01.27.59:712][  1]LogLearning: Display: Subprocess:                     "DistributionSize": 6,
[2026.01.08-01.27.59:718][  1]LogLearning: Display: Subprocess:                     "EncodedSize": 6,
[2026.01.08-01.27.59:721][  1]LogLearning: Display: Subprocess:                     "ModifierSize": 10,
[2026.01.08-01.27.59:725][  1]LogLearning: Display: Subprocess:                     "Type": "And",
[2026.01.08-01.27.59:730][  1]LogLearning: Display: Subprocess:                     "Elements": {
[2026.01.08-01.27.59:749][  1]LogLearning: Display: Subprocess:                         "MoveForward": {
[2026.01.08-01.27.59:753][  1]LogLearning: Display: Subprocess:                             "VectorSize": 1,
[2026.01.08-01.27.59:757][  1]LogLearning: Display: Subprocess:                             "DistributionSize": 2,
[2026.01.08-01.27.59:763][  1]LogLearning: Display: Subprocess:                             "EncodedSize": 2,
[2026.01.08-01.27.59:768][  1]LogLearning: Display: Subprocess:                             "ModifierSize": 3,
[2026.01.08-01.27.59:787][  1]LogLearning: Display: Subprocess:                             "Type": "Continuous",
[2026.01.08-01.27.59:791][  1]LogLearning: Display: Subprocess:                             "Num": 1,
[2026.01.08-01.27.59:795][  1]LogLearning: Display: Subprocess:                             "Index": 0
[2026.01.08-01.27.59:800][  1]LogLearning: Display: Subprocess:                         },
[2026.01.08-01.27.59:803][  1]LogLearning: Display: Subprocess:                         "MoveRight": {
[2026.01.08-01.27.59:808][  1]LogLearning: Display: Subprocess:                             "VectorSize": 1,
[2026.01.08-01.27.59:811][  1]LogLearning: Display: Subprocess:                             "DistributionSize": 2,
[2026.01.08-01.27.59:829][  1]LogLearning: Display: Subprocess:                             "EncodedSize": 2,
[2026.01.08-01.27.59:833][  1]LogLearning: Display: Subprocess:                             "ModifierSize": 3,
[2026.01.08-01.27.59:838][  1]LogLearning: Display: Subprocess:                             "Type": "Continuous",
[2026.01.08-01.27.59:842][  1]LogLearning: Display: Subprocess:                             "Num": 1,
[2026.01.08-01.27.59:846][  1]LogLearning: Display: Subprocess:                             "Index": 1
[2026.01.08-01.27.59:863][  1]LogLearning: Display: Subprocess:                         },
[2026.01.08-01.27.59:867][  1]LogLearning: Display: Subprocess:                         "Turn": {
[2026.01.08-01.27.59:870][  1]LogLearning: Display: Subprocess:                             "VectorSize": 1,
[2026.01.08-01.27.59:875][  1]LogLearning: Display: Subprocess:                             "DistributionSize": 2,
[2026.01.08-01.27.59:878][  1]LogLearning: Display: Subprocess:                             "EncodedSize": 2,
[2026.01.08-01.27.59:881][  1]LogLearning: Display: Subprocess:                             "ModifierSize": 3,
[2026.01.08-01.27.59:886][  1]LogLearning: Display: Subprocess:                             "Type": "Continuous",
[2026.01.08-01.27.59:903][  1]LogLearning: Display: Subprocess:                             "Num": 1,
[2026.01.08-01.27.59:907][  1]LogLearning: Display: Subprocess:                             "Index": 2
[2026.01.08-01.27.59:911][  1]LogLearning: Display: Subprocess:                         }
[2026.01.08-01.27.59:916][  1]LogLearning: Display: Subprocess:                     }
[2026.01.08-01.27.59:919][  1]LogLearning: Display: Subprocess:                 }
[2026.01.08-01.27.59:926][  1]LogLearning: Display: Subprocess:             }
[2026.01.08-01.27.59:943][  1]LogLearning: Display: Subprocess:         ]
[2026.01.08-01.27.59:945][  1]LogLearning: Display: Subprocess:     },
[2026.01.08-01.27.59:949][  1]LogLearning: Display: Subprocess:     "TrainerMethod": "PPO",
[2026.01.08-01.27.59:952][  1]LogLearning: Display: Subprocess:     "TimeStamp": "2026-01-08_01-27-56",
[2026.01.08-01.27.59:957][  1]LogLearning: Display: Subprocess:     "PPOSettings": {
[2026.01.08-01.27.59:960][  1]LogLearning: Display: Subprocess:         "IterationNum": 1000000,
[2026.01.08-01.27.59:978][  1]LogLearning: Display: Subprocess:         "LearningRatePolicy": 0.0003000000142492354,
[2026.01.08-01.27.59:982][  1]LogLearning: Display: Subprocess:         "LearningRateCritic": 0.003000000026077032,
[2026.01.08-01.27.59:986][  1]LogLearning: Display: Subprocess:         "LearningRateDecay": 1,
[2026.01.08-01.27.59:991][  1]LogLearning: Display: Subprocess:         "WeightDecay": 9.999999747378752e-05,
[2026.01.08-01.27.59:997][  1]LogLearning: Display: Subprocess:         "PolicyBatchSize": 2048,
[2026.01.08-01.28.00:002][  1]LogLearning: Display: Subprocess:         "CriticBatchSize": 8192,
[2026.01.08-01.28.00:008][  1]LogLearning: Display: Subprocess:         "PolicyWindow": 16,
[2026.01.08-01.28.00:026][  1]LogLearning: Display: Subprocess:         "IterationsPerGather": 64,
[2026.01.08-01.28.00:030][  1]LogLearning: Display: Subprocess:         "CriticWarmupIterations": 8,
[2026.01.08-01.28.00:035][  1]LogLearning: Display: Subprocess:         "EpsilonClip": 0.30000001192092896,
[2026.01.08-01.28.00:038][  1]LogLearning: Display: Subprocess:         "ActionSurrogateWeight": 1,
[2026.01.08-01.28.00:043][  1]LogLearning: Display: Subprocess:         "ActionRegularizationWeight": 0.0010000000474974513,
[2026.01.08-01.28.00:060][  1]LogLearning: Display: Subprocess:         "ActionEntropyWeight": 0,
[2026.01.08-01.28.00:065][  1]LogLearning: Display: Subprocess:         "ReturnRegularizationWeight": 9.999999747378752e-05,
[2026.01.08-01.28.00:070][  1]LogLearning: Display: Subprocess:         "GaeLambda": 0.949999988079071,
[2026.01.08-01.28.00:075][  1]LogLearning: Display: Subprocess:         "AdvantageNormalization": true,
[2026.01.08-01.28.00:079][  1]LogLearning: Display: Subprocess:         "AdvantageMin": 0,
[2026.01.08-01.28.00:083][  1]LogLearning: Display: Subprocess:         "AdvantageMax": 10,
[2026.01.08-01.28.00:112][  1]LogLearning: Display: Subprocess:         "UseGradNormMaxClipping": false,
[2026.01.08-01.28.00:115][  1]LogLearning: Display: Subprocess:         "GradNormMax": 0.5,
[2026.01.08-01.28.00:120][  1]LogLearning: Display: Subprocess:         "TrimEpisodeStartStepNum": 0,
[2026.01.08-01.28.00:124][  1]LogLearning: Display: Subprocess:         "TrimEpisodeEndStepNum": 0,
[2026.01.08-01.28.00:128][  1]LogLearning: Display: Subprocess:         "Seed": 1234,
[2026.01.08-01.28.00:133][  1]LogLearning: Display: Subprocess:         "DiscountFactor": 0.9950000047683716,
[2026.01.08-01.28.00:153][  1]LogLearning: Display: Subprocess:         "Device": "GPU",
[2026.01.08-01.28.00:157][  1]LogLearning: Display: Subprocess:         "UseTensorBoard": true,
[2026.01.08-01.28.00:161][  1]LogLearning: Display: Subprocess:         "SaveSnapshots": true,
[2026.01.08-01.28.00:166][  1]LogLearning: Display: Subprocess:         "UseMLflow": false,
[2026.01.08-01.28.00:171][  1]LogLearning: Display: Subprocess:         "MLflowTrackingUri": ""
[2026.01.08-01.28.00:194][  1]LogLearning: Display: Subprocess:     },
[2026.01.08-01.28.00:197][  1]LogLearning: Display: Subprocess:     "TempDirectory": "D:/unrealprojects/coop-game-fleep/Intermediate/LearningAgents",
[2026.01.08-01.28.00:202][  1]LogLearning: Display: Subprocess:     "TaskName": "Aggressive-seed-1801914551-750b6e4caaa0",
[2026.01.08-01.28.00:205][  1]LogLearning: Display: Subprocess:     "TaskDirectory": "D:/unrealprojects/coop-game-fleep/Intermediate/LearningAgents/Aggressive-seed-1801914551-750b6e4caaa00",
[2026.01.08-01.28.00:210][  1]LogLearning: Display: Subprocess:     "CommunicationType": "SharedMemory"
[2026.01.08-01.28.00:214][  1]LogLearning: Display: Subprocess: }
[2026.01.08-01.28.00:243][  1]LogLearning: Display: Pushing network...
[2026.01.08-01.28.00:245][  1]LogLearning: Display: Subprocess: INFO: Receiving Policy...
[2026.01.08-01.28.00:249][  1]LogLearning: Display: Subprocess: WARNING: GPU does not support CUDA. Defaulting to CPU training.
[2026.01.08-01.28.00:257][  1]LogLearning: Display: Pushing network...
[2026.01.08-01.28.00:261][  1]LogLearning: Display: Subprocess: INFO: Receiving Critic...
[2026.01.08-01.28.00:284][  1]LogLearning: Display: Subprocess: WARNING: GPU does not support CUDA. Defaulting to CPU training.
[2026.01.08-01.28.00:291][  1]LogLearning: Display: Pushing network...
[2026.01.08-01.28.00:294][  1]LogLearning: Display: Subprocess: INFO: Receiving Encoder...
[2026.01.08-01.28.00:298][  1]LogLearning: Display: Subprocess: WARNING: GPU does not support CUDA. Defaulting to CPU training.
[2026.01.08-01.28.00:304][  1]LogLearning: Display: Pushing network...
[2026.01.08-01.28.00:325][  1]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 4 5 6 7].
[2026.01.08-01.28.00:329][  1]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.00:334][  1]LogTemp: Reset Target for Agent 0 - Target: X=-724.571 Y=-896.451 Z=100.000
[2026.01.08-01.28.00:337][  1]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=642.048 Y=1825.312 Z=100.000, Distance to Target: 3045.593604
[2026.01.08-01.28.00:342][  1]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.00:346][  1]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=-449.782 Y=-983.245 Z=100.000, Distance to Target: 288.170358
[2026.01.08-01.28.00:371][  1]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.00:376][  1]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=-1601.184 Y=304.025 Z=100.000, Distance to Target: 1486.470473
[2026.01.08-01.28.00:381][  1]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.00:384][  1]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=244.697 Y=22.523 Z=100.000, Distance to Target: 1335.661765
[2026.01.08-01.28.00:390][  1]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.00:413][  1]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=-1816.157 Y=330.637 Z=100.000, Distance to Target: 1642.347547
[2026.01.08-01.28.00:416][  1]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.00:420][  1]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=-1348.247 Y=-559.160 Z=100.000, Distance to Target: 709.039461
[2026.01.08-01.28.00:424][  1]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.00:428][  1]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=1705.069 Y=-647.053 Z=100.000, Distance to Target: 2442.406084
[2026.01.08-01.28.00:432][  1]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.00:450][  1]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=86.123 Y=1861.324 Z=100.000, Distance to Target: 2874.464305
[2026.01.08-01.28.01:739][  2]LogTemp: Agent 0 (PlayerPawn_0): Episode complete - max steps reached (1000)
[2026.01.08-01.28.01:741][  2]LogTemp: Agent 1 (PlayerPawn_1): Episode complete - max steps reached (1000)
[2026.01.08-01.28.01:744][  2]LogTemp: Agent 2 (PlayerPawn_2): Episode complete - max steps reached (1000)
[2026.01.08-01.28.01:746][  2]LogTemp: Agent 3 (PlayerPawn_3): Episode complete - max steps reached (1000)
[2026.01.08-01.28.01:748][  2]LogTemp: Agent 4 (PlayerPawn_4): Episode complete - max steps reached (1000)
[2026.01.08-01.28.01:749][  2]LogTemp: Agent 5 (PlayerPawn_5): Episode complete - max steps reached (1000)
[2026.01.08-01.28.01:751][  2]LogTemp: Agent 6 (PlayerPawn_6): Episode complete - max steps reached (1000)
[2026.01.08-01.28.01:753][  2]LogTemp: Agent 7 (PlayerPawn_7): Episode complete - max steps reached (1000)
[2026.01.08-01.28.01:755][  2]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 4 5 6 7].
[2026.01.08-01.28.01:757][  2]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.01:759][  2]LogTemp: Reset Target for Agent 0 - Target: X=1442.488 Y=-211.249 Z=100.000
[2026.01.08-01.28.01:760][  2]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=-405.835 Y=-1726.432 Z=100.000, Distance to Target: 2389.995344
[2026.01.08-01.28.01:779][  2]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.01:782][  2]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=-1232.154 Y=1048.189 Z=100.000, Distance to Target: 2956.331310
[2026.01.08-01.28.01:785][  2]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.01:788][  2]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=-1260.720 Y=-486.526 Z=100.000, Distance to Target: 2717.187669
[2026.01.08-01.28.01:791][  2]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.01:794][  2]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=-681.600 Y=511.185 Z=100.000, Distance to Target: 2243.582403
[2026.01.08-01.28.01:799][  2]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.01:801][  2]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=138.859 Y=-1449.202 Z=100.000, Distance to Target: 1797.769437
[2026.01.08-01.28.01:805][  2]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.01:807][  2]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=694.052 Y=335.887 Z=100.000, Distance to Target: 927.099792
[2026.01.08-01.28.01:809][  2]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.01:813][  2]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=-1431.501 Y=276.437 Z=100.000, Distance to Target: 2915.073077
[2026.01.08-01.28.01:824][  2]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.01:826][  2]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=292.672 Y=-248.482 Z=100.000, Distance to Target: 1150.418224
[2026.01.08-01.28.02:390][514]LogLearning: Display: Pushing Experience...
[2026.01.08-01.28.02:392][514]LogLearning: Display: Subprocess: INFO: Receiving Decoder...
[2026.01.08-01.28.02:393][514]LogLearning: Display: Subprocess: WARNING: GPU does not support CUDA. Defaulting to CPU training.
[2026.01.08-01.28.02:395][514]LogLearning: Display: Subprocess: INFO: Creating PPO Policy...
[2026.01.08-01.28.02:397][514]LogLearning: Display: Subprocess: INFO: Begin Training...
[2026.01.08-01.28.02:401][514]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.28.02:401][514]LogLearning: Display: Subprocess: Episode Num: 20 | Total Step Num: 10000
[2026.01.08-01.28.02:404][514]LogLearning: Display: Subprocess: INFO: Profile| Pull Experience              343ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.08:599][514]LogLearning: Display: Subprocess: INFO: Profile| PPO load tensors               0ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.08:629][514]LogLearning: Display: Subprocess: INFO: Profile| PPO gae                       30ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.08:686][514]LogLearning: Display: Subprocess: INFO: Profile| PPO log prob                  58ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.08:739][514]LogLearning: Display: Subprocess: INFO: Profile| PPO create batches            53ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.43:514][514]LogLearning: Display: Subprocess: INFO: Profile| PPO train                  34775ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.43:515][514]LogLearning: Display: Subprocess: INFO: Profile| Training                   41114ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.43:517][514]LogLearning: Display: Subprocess: INFO: Setting latest networks in communicator... IDs: [0, 1, 2, 3] | Version: 0
[2026.01.08-01.28.43:519][514]LogLearning: Display: Pulling network...
[2026.01.08-01.28.43:525][514]LogLearning: Display: Pulling network...
[2026.01.08-01.28.43:527][514]LogLearning: Display: Pulling network...
[2026.01.08-01.28.43:530][514]LogLearning: Display: Pulling network...
[2026.01.08-01.28.43:530][514]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 4 5 6 7].
[2026.01.08-01.28.43:533][514]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.43:535][514]LogTemp: Reset Target for Agent 0 - Target: X=1596.179 Y=1643.422 Z=100.000
[2026.01.08-01.28.43:536][514]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=69.399 Y=1382.305 Z=100.000, Distance to Target: 1548.947558
[2026.01.08-01.28.43:539][514]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.43:540][514]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=1995.483 Y=1776.482 Z=100.000, Distance to Target: 420.890667
[2026.01.08-01.28.43:541][514]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.43:542][514]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=-1033.296 Y=-1339.579 Z=100.000, Distance to Target: 3976.484985
[2026.01.08-01.28.43:543][514]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.43:544][514]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=1190.039 Y=555.864 Z=100.000, Distance to Target: 1160.918343
[2026.01.08-01.28.43:546][514]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.43:549][514]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=234.077 Y=1956.908 Z=100.000, Distance to Target: 1397.710800
[2026.01.08-01.28.43:551][514]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.43:553][514]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=-1735.954 Y=-328.806 Z=100.000, Distance to Target: 3872.052813
[2026.01.08-01.28.43:555][514]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.43:556][514]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=-1804.682 Y=-810.633 Z=100.000, Distance to Target: 4193.833002
[2026.01.08-01.28.43:558][514]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.43:560][514]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=-1900.143 Y=-1084.933 Z=100.000, Distance to Target: 4434.883310
[2026.01.08-01.28.43:568][519]LogTemp: Agent 1 (PlayerPawn_1): Episode complete - out of bounds
[2026.01.08-01.28.43:570][519]LogLearning: Display: Learning Agents Manager: Resetting Agents [1].
[2026.01.08-01.28.43:572][519]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.43:574][519]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=155.095 Y=-1600.330 Z=100.000, Distance to Target: 3549.457008
[2026.01.08-01.28.44:539][515]LogTemp: Agent 0 (PlayerPawn_0): Episode complete - max steps reached (1000)
[2026.01.08-01.28.44:541][515]LogTemp: Agent 2 (PlayerPawn_2): Episode complete - max steps reached (1000)
[2026.01.08-01.28.44:542][515]LogTemp: Agent 3 (PlayerPawn_3): Episode complete - max steps reached (1000)
[2026.01.08-01.28.44:544][515]LogTemp: Agent 4 (PlayerPawn_4): Episode complete - max steps reached (1000)
[2026.01.08-01.28.44:544][515]LogTemp: Agent 5 (PlayerPawn_5): Episode complete - max steps reached (1000)
[2026.01.08-01.28.44:546][515]LogTemp: Agent 6 (PlayerPawn_6): Episode complete - max steps reached (1000)
[2026.01.08-01.28.44:546][515]LogTemp: Agent 7 (PlayerPawn_7): Episode complete - max steps reached (1000)
[2026.01.08-01.28.44:548][515]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 2 3 4 5 6 7].
[2026.01.08-01.28.44:549][515]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.44:551][515]LogTemp: Reset Target for Agent 0 - Target: X=-1371.319 Y=403.272 Z=100.000
[2026.01.08-01.28.44:551][515]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=707.358 Y=-146.672 Z=100.000, Distance to Target: 2150.194265
[2026.01.08-01.28.44:553][515]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.44:554][515]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=-1443.464 Y=-1672.475 Z=100.000, Distance to Target: 2077.000433
[2026.01.08-01.28.44:555][515]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.44:557][515]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=335.032 Y=310.984 Z=100.000, Distance to Target: 1708.844800
[2026.01.08-01.28.44:559][515]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.44:559][515]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=-1488.144 Y=-846.645 Z=100.000, Distance to Target: 1255.363910
[2026.01.08-01.28.44:561][515]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.44:562][515]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=603.107 Y=809.290 Z=100.000, Distance to Target: 2015.739721
[2026.01.08-01.28.44:564][515]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.44:564][515]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=492.264 Y=637.898 Z=100.000, Distance to Target: 1878.293990
[2026.01.08-01.28.44:566][515]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.44:567][515]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=318.064 Y=1822.748 Z=100.000, Distance to Target: 2206.564762
[2026.01.08-01.28.44:574][520]LogTemp: Agent 1 (PlayerPawn_1): Episode complete - max steps reached (1000)
[2026.01.08-01.28.44:575][520]LogLearning: Display: Learning Agents Manager: Resetting Agents [1].
[2026.01.08-01.28.44:577][520]LogTemp: Health reset to: 100.0
[2026.01.08-01.28.44:578][520]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=-1016.083 Y=-1456.648 Z=100.000, Distance to Target: 1893.540380
[2026.01.08-01.28.45:068][ 27]LogLearning: Display: Pushing Experience...
[2026.01.08-01.28.45:070][ 27]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.28.45:071][ 27]LogLearning: Display: Subprocess: Iter:       0 | Avg Rew: 0.42336 | Avg Rew Sum: 211.57098 | Avg Return: 45.59277 | Avg Episode Len: 500.00000 | Batch Size: 1
[2026.01.08-01.28.45:072][ 27]LogLearning: Display: Subprocess: INFO: Saved Policy Snapshot to: "D:/unrealprojects/coop-game-fleep/Intermediate/LearningAgents/Aggressive-seed-1801914551-750b6e4caaa00\Snapshots\policy_0.bin"
[2026.01.08-01.28.45:074][ 27]LogLearning: Display: Subprocess: INFO: Saved Critic Snapshot to: "D:/unrealprojects/coop-game-fleep/Intermediate/LearningAgents/Aggressive-seed-1801914551-750b6e4caaa00\Snapshots\critic_0.bin"
[2026.01.08-01.28.45:075][ 27]LogLearning: Display: Subprocess: INFO: Saved Encoder Snapshot to: "D:/unrealprojects/coop-game-fleep/Intermediate/LearningAgents/Aggressive-seed-1801914551-750b6e4caaa00\Snapshots\encoder_0.bin"
[2026.01.08-01.28.45:076][ 27]LogLearning: Display: Subprocess: INFO: Saved Decoder Snapshot to: "D:/unrealprojects/coop-game-fleep/Intermediate/LearningAgents/Aggressive-seed-1801914551-750b6e4caaa00\Snapshots\decoder_0.bin"
[2026.01.08-01.28.45:076][ 27]LogLearning: Display: Subprocess: INFO: Profile| Logging                       13ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.45:081][ 27]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.28.45:081][ 27]LogLearning: Display: Subprocess: Episode Num: 21 | Total Step Num: 10000
[2026.01.08-01.28.45:082][ 27]LogLearning: Display: Subprocess: INFO: Profile| Pull Experience             1532ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.45:085][ 27]LogLearning: Display: Subprocess: INFO: Profile| PPO load tensors               1ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.45:103][ 27]LogLearning: Display: Subprocess: INFO: Profile| PPO gae                       28ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.45:156][ 27]LogLearning: Display: Subprocess: INFO: Profile| PPO log prob                  53ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.28.45:243][ 27]LogLearning: Display: Subprocess: INFO: Profile| PPO create batches            86ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.19:986][ 27]LogLearning: Display: Subprocess: INFO: Profile| PPO train                  34744ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.19:987][ 27]LogLearning: Display: Subprocess: INFO: Profile| Training                   34911ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.19:989][ 27]LogLearning: Display: Subprocess: INFO: Setting latest networks in communicator... IDs: [0, 1, 2, 3] | Version: 64
[2026.01.08-01.29.19:993][ 27]LogLearning: Display: Pulling network...
[2026.01.08-01.29.19:998][ 27]LogLearning: Display: Pulling network...
[2026.01.08-01.29.20:001][ 27]LogLearning: Display: Pulling network...
[2026.01.08-01.29.20:005][ 27]LogLearning: Display: Pulling network...
[2026.01.08-01.29.20:006][ 27]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 4 5 6 7].
[2026.01.08-01.29.20:008][ 27]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.20:010][ 27]LogTemp: Reset Target for Agent 0 - Target: X=-471.267 Y=1120.823 Z=100.000
[2026.01.08-01.29.20:014][ 27]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=531.205 Y=1184.423 Z=100.000, Distance to Target: 1004.487559
[2026.01.08-01.29.20:017][ 27]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.20:020][ 27]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=-141.667 Y=-1061.006 Z=100.000, Distance to Target: 2206.584375
[2026.01.08-01.29.20:023][ 27]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.20:026][ 27]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=315.012 Y=839.076 Z=100.000, Distance to Target: 835.233929
[2026.01.08-01.29.20:030][ 27]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.20:033][ 27]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=1793.329 Y=-96.133 Z=100.000, Distance to Target: 2570.870536
[2026.01.08-01.29.20:037][ 27]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.20:040][ 27]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=-1006.439 Y=-1565.905 Z=100.000, Distance to Target: 2739.509769
[2026.01.08-01.29.20:042][ 27]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.20:047][ 27]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=1059.786 Y=-886.807 Z=100.000, Distance to Target: 2524.816560
[2026.01.08-01.29.20:049][ 27]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.20:051][ 27]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=-1152.562 Y=903.897 Z=100.000, Distance to Target: 714.996302
[2026.01.08-01.29.20:053][ 27]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.20:056][ 27]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=127.384 Y=769.249 Z=100.000, Distance to Target: 694.252704
[2026.01.08-01.29.21:027][ 13]LogTemp: Agent 2 (PlayerPawn_2): Episode complete - reached target
[2026.01.08-01.29.21:029][ 13]LogTemp: Agent 2 reached target! Reward: 100.000000
[2026.01.08-01.29.21:030][ 13]LogLearning: Display: Learning Agents Manager: Resetting Agents [2].
[2026.01.08-01.29.21:032][ 13]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.21:033][ 13]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=-1564.440 Y=1072.603 Z=100.000, Distance to Target: 1094.235911
[2026.01.08-01.29.21:050][ 28]LogTemp: Agent 0 (PlayerPawn_0): Episode complete - max steps reached (1000)
[2026.01.08-01.29.21:051][ 28]LogTemp: Agent 1 (PlayerPawn_1): Episode complete - max steps reached (1000)
[2026.01.08-01.29.21:052][ 28]LogTemp: Agent 3 (PlayerPawn_3): Episode complete - max steps reached (1000)
[2026.01.08-01.29.21:054][ 28]LogTemp: Agent 4 (PlayerPawn_4): Episode complete - max steps reached (1000)
[2026.01.08-01.29.21:054][ 28]LogTemp: Agent 5 (PlayerPawn_5): Episode complete - max steps reached (1000)
[2026.01.08-01.29.21:056][ 28]LogTemp: Agent 6 (PlayerPawn_6): Episode complete - max steps reached (1000)
[2026.01.08-01.29.21:056][ 28]LogTemp: Agent 7 (PlayerPawn_7): Episode complete - max steps reached (1000)
[2026.01.08-01.29.21:059][ 28]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 3 4 5 6 7].
[2026.01.08-01.29.21:060][ 28]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.21:062][ 28]LogTemp: Reset Target for Agent 0 - Target: X=-1159.642 Y=351.634 Z=100.000
[2026.01.08-01.29.21:064][ 28]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=1017.060 Y=-673.177 Z=100.000, Distance to Target: 2405.882549
[2026.01.08-01.29.21:067][ 28]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.21:070][ 28]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=-479.934 Y=1336.283 Z=100.000, Distance to Target: 1196.468681
[2026.01.08-01.29.21:072][ 28]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.21:075][ 28]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=640.339 Y=-1680.044 Z=100.000, Distance to Target: 2714.341628
[2026.01.08-01.29.21:077][ 28]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.21:079][ 28]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=-1043.672 Y=667.318 Z=100.000, Distance to Target: 336.311038
[2026.01.08-01.29.21:081][ 28]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.21:083][ 28]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=734.825 Y=-1250.221 Z=100.000, Distance to Target: 2480.916422
[2026.01.08-01.29.21:085][ 28]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.21:087][ 28]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=-1402.936 Y=1743.278 Z=100.000, Distance to Target: 1412.750779
[2026.01.08-01.29.21:089][ 28]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.21:091][ 28]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=1145.604 Y=-296.945 Z=100.000, Distance to Target: 2394.747457
[2026.01.08-01.29.21:357][291]LogTemp: Agent 4 (PlayerPawn_4): Episode complete - reached target
[2026.01.08-01.29.21:358][291]LogTemp: Agent 4 reached target! Reward: 100.000000
[2026.01.08-01.29.21:360][291]LogLearning: Display: Learning Agents Manager: Resetting Agents [4].
[2026.01.08-01.29.21:360][291]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.21:362][291]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=1875.729 Y=-594.073 Z=100.000, Distance to Target: 3179.282870
[2026.01.08-01.29.21:595][540]LogLearning: Display: Pushing Experience...
[2026.01.08-01.29.21:598][540]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.29.21:599][540]LogLearning: Display: Subprocess: Iter:      64 | Avg Rew: 0.46146 | Avg Rew Sum: 228.66215 | Avg Return: 46.73886 | Avg Episode Len: 476.19048 | Batch Size: 1
[2026.01.08-01.29.21:600][540]LogLearning: Display: Subprocess: INFO: Profile| Logging                        5ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.21:604][540]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.29.21:605][540]LogLearning: Display: Subprocess: Episode Num: 21 | Total Step Num: 10000
[2026.01.08-01.29.21:606][540]LogLearning: Display: Subprocess: INFO: Profile| Pull Experience             1594ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.21:608][540]LogLearning: Display: Subprocess: INFO: Profile| PPO load tensors               0ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.21:635][540]LogLearning: Display: Subprocess: INFO: Profile| PPO gae                       30ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.21:692][540]LogLearning: Display: Subprocess: INFO: Profile| PPO log prob                  58ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.21:743][540]LogLearning: Display: Subprocess: INFO: Profile| PPO create batches            51ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.56:115][540]LogLearning: Display: Subprocess: INFO: Profile| PPO train                  34372ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.56:129][540]LogLearning: Display: Subprocess: INFO: Profile| Training                   34511ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.56:130][540]LogLearning: Display: Subprocess: INFO: Setting latest networks in communicator... IDs: [0, 1, 2, 3] | Version: 128
[2026.01.08-01.29.56:133][540]LogLearning: Display: Pulling network...
[2026.01.08-01.29.56:136][540]LogLearning: Display: Pulling network...
[2026.01.08-01.29.56:140][540]LogLearning: Display: Pulling network...
[2026.01.08-01.29.56:144][540]LogLearning: Display: Pulling network...
[2026.01.08-01.29.56:145][540]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 4 5 6 7].
[2026.01.08-01.29.56:146][540]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.56:147][540]LogTemp: Reset Target for Agent 0 - Target: X=-486.038 Y=-1960.692 Z=100.000
[2026.01.08-01.29.56:148][540]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=-80.630 Y=1322.733 Z=100.000, Distance to Target: 3308.358706
[2026.01.08-01.29.56:149][540]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.56:151][540]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=257.515 Y=-1055.513 Z=100.000, Distance to Target: 1171.417945
[2026.01.08-01.29.56:154][540]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.56:157][540]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=685.873 Y=-1423.688 Z=100.000, Distance to Target: 1289.087971
[2026.01.08-01.29.56:181][540]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.56:184][540]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=-3.601 Y=-845.790 Z=100.000, Distance to Target: 1214.805242
[2026.01.08-01.29.56:186][540]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.56:189][540]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=-653.401 Y=12.391 Z=100.000, Distance to Target: 1980.168220
[2026.01.08-01.29.56:213][540]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.56:216][540]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=1565.905 Y=-1584.582 Z=100.000, Distance to Target: 2086.127083
[2026.01.08-01.29.56:217][540]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.56:221][540]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=850.551 Y=52.675 Z=100.000, Distance to Target: 2416.633298
[2026.01.08-01.29.56:242][540]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.56:266][540]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=547.197 Y=1891.598 Z=100.000, Distance to Target: 3988.447685
[2026.01.08-01.29.56:909][179]LogTemp: Agent 5 (PlayerPawn_5): Episode complete - out of bounds
[2026.01.08-01.29.56:919][179]LogLearning: Display: Learning Agents Manager: Resetting Agents [5].
[2026.01.08-01.29.56:920][179]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.56:922][179]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=-17.884 Y=1516.953 Z=100.000, Distance to Target: 3509.014650
[2026.01.08-01.29.57:123][390]LogTemp: Agent 1 (PlayerPawn_1): Episode complete - reached target
[2026.01.08-01.29.57:136][390]LogTemp: Agent 1 reached target! Reward: 100.000000
[2026.01.08-01.29.57:137][390]LogLearning: Display: Learning Agents Manager: Resetting Agents [1].
[2026.01.08-01.29.57:139][390]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.57:140][390]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=959.685 Y=-1910.520 Z=100.000, Distance to Target: 1446.593149
[2026.01.08-01.29.57:233][488]LogTemp: Agent 2 (PlayerPawn_2): Episode complete - out of bounds
[2026.01.08-01.29.57:253][488]LogLearning: Display: Learning Agents Manager: Resetting Agents [2].
[2026.01.08-01.29.57:255][488]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.57:255][488]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=-472.488 Y=1127.293 Z=100.000, Distance to Target: 3088.014522
[2026.01.08-01.29.57:293][525]LogTemp: Agent 3 (PlayerPawn_3): Episode complete - reached target
[2026.01.08-01.29.57:293][525]LogTemp: Agent 3 reached target! Reward: 100.000000
[2026.01.08-01.29.57:295][525]LogLearning: Display: Learning Agents Manager: Resetting Agents [3].
[2026.01.08-01.29.57:296][525]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.57:297][525]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=-602.741 Y=-1052.339 Z=100.000, Distance to Target: 915.819055
[2026.01.08-01.29.57:313][541]LogTemp: Agent 0 (PlayerPawn_0): Episode complete - max steps reached (1000)
[2026.01.08-01.29.57:315][541]LogTemp: Agent 4 (PlayerPawn_4): Episode complete - max steps reached (1000)
[2026.01.08-01.29.57:315][541]LogTemp: Agent 6 (PlayerPawn_6): Episode complete - max steps reached (1000)
[2026.01.08-01.29.57:317][541]LogTemp: Agent 7 (PlayerPawn_7): Episode complete - max steps reached (1000)
[2026.01.08-01.29.57:317][541]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 4 6 7].
[2026.01.08-01.29.57:319][541]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.57:320][541]LogTemp: Reset Target for Agent 0 - Target: X=-1857.173 Y=995.331 Z=100.000
[2026.01.08-01.29.57:321][541]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=508.988 Y=-697.226 Z=100.000, Distance to Target: 2909.203535
[2026.01.08-01.29.57:322][541]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.57:323][541]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=1209.082 Y=-410.962 Z=100.000, Distance to Target: 3373.363862
[2026.01.08-01.29.57:324][541]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.57:326][541]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=1383.038 Y=1205.298 Z=100.000, Distance to Target: 3247.007060
[2026.01.08-01.29.57:326][541]LogTemp: Health reset to: 100.0
[2026.01.08-01.29.57:328][541]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=108.219 Y=342.845 Z=100.000, Distance to Target: 2070.870202
[2026.01.08-01.29.57:824][ 53]LogLearning: Display: Pushing Experience...
[2026.01.08-01.29.57:832][ 53]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.29.57:833][ 53]LogLearning: Display: Subprocess: Iter:     128 | Avg Rew: 0.52521 | Avg Rew Sum: 245.97608 | Avg Return: 40.52887 | Avg Episode Len: 476.19048 | Batch Size: 1
[2026.01.08-01.29.57:834][ 53]LogLearning: Display: Subprocess: INFO: Profile| Logging                        6ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.57:837][ 53]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.29.57:839][ 53]LogLearning: Display: Subprocess: Episode Num: 22 | Total Step Num: 10000
[2026.01.08-01.29.57:839][ 53]LogLearning: Display: Subprocess: INFO: Profile| Pull Experience             1688ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.57:841][ 53]LogLearning: Display: Subprocess: INFO: Profile| PPO load tensors               0ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.57:866][ 53]LogLearning: Display: Subprocess: INFO: Profile| PPO gae                       29ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.57:921][ 53]LogLearning: Display: Subprocess: INFO: Profile| PPO log prob                  55ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.29.57:974][ 53]LogLearning: Display: Subprocess: INFO: Profile| PPO create batches            52ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.30.31:835][ 53]LogLearning: Display: Subprocess: INFO: Profile| PPO train                  33862ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.30.31:837][ 53]LogLearning: Display: Subprocess: INFO: Profile| Training                   33998ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.30.31:838][ 53]LogLearning: Display: Subprocess: INFO: Setting latest networks in communicator... IDs: [0, 1, 2, 3] | Version: 192
[2026.01.08-01.30.31:841][ 53]LogLearning: Display: Pulling network...
[2026.01.08-01.30.31:846][ 53]LogLearning: Display: Pulling network...
[2026.01.08-01.30.31:851][ 53]LogLearning: Display: Pulling network...
[2026.01.08-01.30.31:854][ 53]LogLearning: Display: Pulling network...
[2026.01.08-01.30.31:855][ 53]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 4 5 6 7].
[2026.01.08-01.30.31:856][ 53]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.31:858][ 53]LogTemp: Reset Target for Agent 0 - Target: X=-137.516 Y=-698.202 Z=100.000
[2026.01.08-01.30.31:858][ 53]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=-1349.834 Y=-830.287 Z=100.000, Distance to Target: 1219.491461
[2026.01.08-01.30.31:860][ 53]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.31:862][ 53]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=1616.321 Y=-781.213 Z=100.000, Distance to Target: 1755.801073
[2026.01.08-01.30.31:863][ 53]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.31:865][ 53]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=-556.352 Y=1661.123 Z=100.000, Distance to Target: 2396.213323
[2026.01.08-01.30.31:867][ 53]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.31:869][ 53]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=-1637.806 Y=111.148 Z=100.000, Distance to Target: 1704.675547
[2026.01.08-01.30.31:870][ 53]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.31:872][ 53]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=-429.273 Y=282.174 Z=100.000, Distance to Target: 1022.868721
[2026.01.08-01.30.31:874][ 53]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.31:878][ 53]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=-749.718 Y=1918.821 Z=100.000, Distance to Target: 2687.675888
[2026.01.08-01.30.31:879][ 53]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.31:881][ 53]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=552.690 Y=-1338.969 Z=100.000, Distance to Target: 941.789296
[2026.01.08-01.30.31:882][ 53]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.31:884][ 53]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=-1478.378 Y=1732.658 Z=100.000, Distance to Target: 2776.146827
[2026.01.08-01.30.32:428][615]LogTemp: Agent 6 (PlayerPawn_6): Episode complete - reached target
[2026.01.08-01.30.32:432][615]LogTemp: Agent 6 reached target! Reward: 100.000000
[2026.01.08-01.30.32:434][615]LogLearning: Display: Learning Agents Manager: Resetting Agents [6].
[2026.01.08-01.30.32:435][615]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.32:437][615]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=1673.208 Y=1277.688 Z=100.000, Distance to Target: 2680.086798
[2026.01.08-01.30.32:570][753]LogTemp: Agent 4 (PlayerPawn_4): Episode complete - reached target
[2026.01.08-01.30.32:572][753]LogTemp: Agent 4 reached target! Reward: 100.000000
[2026.01.08-01.30.32:573][753]LogLearning: Display: Learning Agents Manager: Resetting Agents [4].
[2026.01.08-01.30.32:574][753]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.32:575][753]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=1746.086 Y=-186.224 Z=100.000, Distance to Target: 1951.942487
[2026.01.08-01.30.32:869][ 54]LogTemp: Agent 0 (PlayerPawn_0): Episode complete - max steps reached (1000)
[2026.01.08-01.30.32:872][ 54]LogTemp: Agent 1 (PlayerPawn_1): Episode complete - max steps reached (1000)
[2026.01.08-01.30.32:874][ 54]LogTemp: Agent 2 (PlayerPawn_2): Episode complete - max steps reached (1000)
[2026.01.08-01.30.32:877][ 54]LogTemp: Agent 3 (PlayerPawn_3): Episode complete - max steps reached (1000)
[2026.01.08-01.30.32:880][ 54]LogTemp: Agent 5 (PlayerPawn_5): Episode complete - max steps reached (1000)
[2026.01.08-01.30.32:882][ 54]LogTemp: Agent 7 (PlayerPawn_7): Episode complete - max steps reached (1000)
[2026.01.08-01.30.32:885][ 54]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 5 7].
[2026.01.08-01.30.32:888][ 54]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.32:892][ 54]LogTemp: Reset Target for Agent 0 - Target: X=-751.671 Y=-185.492 Z=100.000
[2026.01.08-01.30.32:896][ 54]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=1236.793 Y=1953.978 Z=100.000, Distance to Target: 2920.842150
[2026.01.08-01.30.32:901][ 54]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.32:904][ 54]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=-1593.860 Y=-1155.248 Z=100.000, Distance to Target: 1284.409973
[2026.01.08-01.30.32:907][ 54]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.32:909][ 54]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=-363.475 Y=694.662 Z=100.000, Distance to Target: 961.959741
[2026.01.08-01.30.32:911][ 54]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.32:913][ 54]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=-47.670 Y=-1313.700 Z=100.000, Distance to Target: 1329.838759
[2026.01.08-01.30.32:914][ 54]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.32:916][ 54]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=-444.411 Y=-41.566 Z=100.000, Distance to Target: 339.298351
[2026.01.08-01.30.32:918][ 54]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.32:923][ 54]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=1043.794 Y=-1072.726 Z=100.000, Distance to Target: 2002.717845
[2026.01.08-01.30.33:132][261]LogTemp: Agent 5 (PlayerPawn_5): Episode complete - reached target
[2026.01.08-01.30.33:132][261]LogTemp: Agent 5 reached target! Reward: 100.000000
[2026.01.08-01.30.33:134][261]LogLearning: Display: Learning Agents Manager: Resetting Agents [5].
[2026.01.08-01.30.33:135][261]LogTemp: Health reset to: 100.0
[2026.01.08-01.30.33:136][261]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=-206.244 Y=1836.909 Z=100.000, Distance to Target: 2094.658581
[2026.01.08-01.30.33:439][566]LogLearning: Display: Pushing Experience...
[2026.01.08-01.30.33:442][566]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.30.33:443][566]LogLearning: Display: Subprocess: Iter:     192 | Avg Rew: 0.53814 | Avg Rew Sum: 252.65593 | Avg Return: 51.41291 | Avg Episode Len: 454.54545 | Batch Size: 1
[2026.01.08-01.30.33:445][566]LogLearning: Display: Subprocess: INFO: Profile| Logging                        5ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.30.33:449][566]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.30.33:449][566]LogLearning: Display: Subprocess: Episode Num: 22 | Total Step Num: 10000
[2026.01.08-01.30.33:451][566]LogLearning: Display: Subprocess: INFO: Profile| Pull Experience             1588ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.30.33:451][566]LogLearning: Display: Subprocess: INFO: Profile| PPO load tensors               0ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.30.33:475][566]LogLearning: Display: Subprocess: INFO: Profile| PPO gae                       28ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.30.33:527][566]LogLearning: Display: Subprocess: INFO: Profile| PPO log prob                  51ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.30.33:578][566]LogLearning: Display: Subprocess: INFO: Profile| PPO create batches            51ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.08:066][566]LogLearning: Display: Pulling network...
[2026.01.08-01.31.08:067][566]LogLearning: Display: Subprocess: INFO: Profile| PPO train                  34489ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.08:071][566]LogLearning: Display: Subprocess: INFO: Profile| Training                   34619ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.08:073][566]LogLearning: Display: Subprocess: INFO: Setting latest networks in communicator... IDs: [0, 1, 2, 3] | Version: 256
[2026.01.08-01.31.08:078][566]LogLearning: Display: Pulling network...
[2026.01.08-01.31.08:082][566]LogLearning: Display: Pulling network...
[2026.01.08-01.31.08:084][566]LogLearning: Display: Pulling network...
[2026.01.08-01.31.08:085][566]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 4 5 6 7].
[2026.01.08-01.31.08:086][566]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.08:088][566]LogTemp: Reset Target for Agent 0 - Target: X=-135.075 Y=-1960.448 Z=100.000
[2026.01.08-01.31.08:088][566]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=-799.158 Y=-1631.458 Z=100.000, Distance to Target: 741.107296
[2026.01.08-01.31.08:091][566]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.08:093][566]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=-1462.020 Y=934.538 Z=100.000, Distance to Target: 3184.607633
[2026.01.08-01.31.08:094][566]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.08:097][566]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=1193.213 Y=-1296.365 Z=100.000, Distance to Target: 1485.043490
[2026.01.08-01.31.08:099][566]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.08:100][566]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=-579.669 Y=-796.838 Z=100.000, Distance to Target: 1245.652850
[2026.01.08-01.31.08:102][566]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.08:104][566]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=-977.386 Y=1160.497 Z=100.000, Distance to Target: 3232.612707
[2026.01.08-01.31.08:106][566]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.08:108][566]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=-1340.068 Y=-1681.143 Z=100.000, Distance to Target: 1236.939399
[2026.01.08-01.31.08:110][566]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.08:112][566]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=1180.273 Y=-1850.215 Z=100.000, Distance to Target: 1319.958747
[2026.01.08-01.31.08:114][566]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.08:116][566]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=-624.836 Y=-1087.619 Z=100.000, Distance to Target: 1000.848105
[2026.01.08-01.31.08:526][972]LogTemp: Agent 6 (PlayerPawn_6): Episode complete - out of bounds
[2026.01.08-01.31.08:528][972]LogLearning: Display: Learning Agents Manager: Resetting Agents [6].
[2026.01.08-01.31.08:529][972]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.08:531][972]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=1814.569 Y=1103.488 Z=100.000, Distance to Target: 3631.641312
[2026.01.08-01.31.08:767][175]LogTemp: Agent 0 (PlayerPawn_0): Episode complete - reached target
[2026.01.08-01.31.08:772][175]LogTemp: Agent 0 reached target! Reward: 100.000000
[2026.01.08-01.31.08:775][175]LogLearning: Display: Learning Agents Manager: Resetting Agents [0].
[2026.01.08-01.31.08:776][175]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.08:778][175]LogTemp: Reset Target for Agent 0 - Target: X=235.664 Y=123.966 Z=100.000
[2026.01.08-01.31.08:781][175]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=-359.935 Y=-345.408 Z=100.000, Distance to Target: 758.321136
[2026.01.08-01.31.09:232][567]LogTemp: Agent 1 (PlayerPawn_1): Episode complete - max steps reached (1000)
[2026.01.08-01.31.09:232][567]LogTemp: Agent 2 (PlayerPawn_2): Episode complete - max steps reached (1000)
[2026.01.08-01.31.09:234][567]LogTemp: Agent 3 (PlayerPawn_3): Episode complete - max steps reached (1000)
[2026.01.08-01.31.09:236][567]LogTemp: Agent 4 (PlayerPawn_4): Episode complete - max steps reached (1000)
[2026.01.08-01.31.09:239][567]LogTemp: Agent 5 (PlayerPawn_5): Episode complete - max steps reached (1000)
[2026.01.08-01.31.09:241][567]LogTemp: Agent 7 (PlayerPawn_7): Episode complete - max steps reached (1000)
[2026.01.08-01.31.09:243][567]LogLearning: Display: Learning Agents Manager: Resetting Agents [1 2 3 4 5 7].
[2026.01.08-01.31.09:245][567]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.09:246][567]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=-953.093 Y=-1933.103 Z=100.000, Distance to Target: 2375.853234
[2026.01.08-01.31.09:248][567]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.09:248][567]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=982.513 Y=284.493 Z=100.000, Distance to Target: 763.906087
[2026.01.08-01.31.09:250][567]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.09:253][567]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=308.908 Y=-1784.417 Z=100.000, Distance to Target: 1909.788521
[2026.01.08-01.31.09:255][567]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.09:255][567]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=1240.822 Y=-127.506 Z=100.000, Distance to Target: 1036.137291
[2026.01.08-01.31.09:256][567]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.09:257][567]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=1025.361 Y=-86.734 Z=100.000, Distance to Target: 817.322243
[2026.01.08-01.31.09:259][567]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.09:259][567]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=1739.006 Y=-1794.305 Z=100.000, Distance to Target: 2437.170968
[2026.01.08-01.31.09:441][741]LogTemp: Agent 0 (PlayerPawn_0): Episode complete - reached target
[2026.01.08-01.31.09:443][741]LogTemp: Agent 0 reached target! Reward: 100.000000
[2026.01.08-01.31.09:444][741]LogLearning: Display: Learning Agents Manager: Resetting Agents [0].
[2026.01.08-01.31.09:446][741]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.09:448][741]LogTemp: Reset Target for Agent 0 - Target: X=-756.310 Y=-1358.135 Z=100.000
[2026.01.08-01.31.09:451][741]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=737.876 Y=-1946.532 Z=100.000, Distance to Target: 1605.865244
[2026.01.08-01.31.09:702][973]LogTemp: Agent 6 (PlayerPawn_6): Episode complete - max steps reached (1000)
[2026.01.08-01.31.09:705][973]LogLearning: Display: Learning Agents Manager: Resetting Agents [6].
[2026.01.08-01.31.09:706][973]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.09:707][973]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=-1601.550 Y=-1297.220 Z=100.000, Distance to Target: 847.432764
[2026.01.08-01.31.09:800][ 59]LogTemp: Agent 1 (PlayerPawn_1): Episode complete - reached target
[2026.01.08-01.31.09:801][ 59]LogTemp: Agent 1 reached target! Reward: 100.000000
[2026.01.08-01.31.09:803][ 59]LogLearning: Display: Learning Agents Manager: Resetting Agents [1].
[2026.01.08-01.31.09:804][ 59]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.09:805][ 59]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=783.776 Y=-1590.930 Z=100.000, Distance to Target: 1557.581007
[2026.01.08-01.31.09:828][ 79]LogLearning: Display: Pushing Experience...
[2026.01.08-01.31.09:831][ 79]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.31.09:832][ 79]LogLearning: Display: Subprocess: Iter:     256 | Avg Rew: 0.73915 | Avg Rew Sum: 286.50047 | Avg Return: 63.01715 | Avg Episode Len: 454.54545 | Batch Size: 1
[2026.01.08-01.31.09:834][ 79]LogLearning: Display: Subprocess: INFO: Profile| Logging                        5ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.09:837][ 79]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.31.09:838][ 79]LogLearning: Display: Subprocess: Episode Num: 22 | Total Step Num: 10000
[2026.01.08-01.31.09:839][ 79]LogLearning: Display: Subprocess: INFO: Profile| Pull Experience             1746ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.09:840][ 79]LogLearning: Display: Subprocess: INFO: Profile| PPO load tensors               0ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.09:867][ 79]LogLearning: Display: Subprocess: INFO: Profile| PPO gae                       30ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.09:921][ 79]LogLearning: Display: Subprocess: INFO: Profile| PPO log prob                  54ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.09:971][ 79]LogLearning: Display: Subprocess: INFO: Profile| PPO create batches            51ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.44:987][ 79]LogLearning: Display: Pulling network...
[2026.01.08-01.31.44:989][ 79]LogLearning: Display: Subprocess: INFO: Profile| PPO train                  35015ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.44:990][ 79]LogLearning: Display: Subprocess: INFO: Profile| Training                   35151ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.44:991][ 79]LogLearning: Display: Subprocess: INFO: Setting latest networks in communicator... IDs: [0, 1, 2, 3] | Version: 320
[2026.01.08-01.31.44:994][ 79]LogLearning: Display: Pulling network...
[2026.01.08-01.31.44:997][ 79]LogLearning: Display: Pulling network...
[2026.01.08-01.31.44:999][ 79]LogLearning: Display: Pulling network...
[2026.01.08-01.31.45:001][ 79]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 4 5 6 7].
[2026.01.08-01.31.45:003][ 79]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.45:004][ 79]LogTemp: Reset Target for Agent 0 - Target: X=1724.601 Y=-1117.527 Z=100.000
[2026.01.08-01.31.45:007][ 79]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=1379.498 Y=576.128 Z=100.000, Distance to Target: 1728.457224
[2026.01.08-01.31.45:008][ 79]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.45:011][ 79]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=1143.895 Y=519.242 Z=100.000, Distance to Target: 1736.730047
[2026.01.08-01.31.45:028][ 79]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.45:031][ 79]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=-181.097 Y=-70.742 Z=100.000, Distance to Target: 2174.268330
[2026.01.08-01.31.45:033][ 79]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.45:034][ 79]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=708.335 Y=-375.072 Z=100.000, Distance to Target: 1258.584784
[2026.01.08-01.31.45:036][ 79]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.45:039][ 79]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=-638.997 Y=-48.769 Z=100.000, Distance to Target: 2594.000378
[2026.01.08-01.31.45:058][ 79]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.45:060][ 79]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=1018.281 Y=606.769 Z=100.000, Distance to Target: 1863.353127
[2026.01.08-01.31.45:061][ 79]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.45:063][ 79]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=1564.562 Y=1246.193 Z=100.000, Distance to Target: 2369.131353
[2026.01.08-01.31.45:066][ 79]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.45:067][ 79]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=-638.142 Y=1054.292 Z=100.000, Distance to Target: 3209.260547
[2026.01.08-01.31.46:073][ 80]LogTemp: Agent 0 (PlayerPawn_0): Episode complete - max steps reached (1000)
[2026.01.08-01.31.46:109][ 80]LogTemp: Agent 1 (PlayerPawn_1): Episode complete - max steps reached (1000)
[2026.01.08-01.31.46:123][ 80]LogTemp: Agent 2 (PlayerPawn_2): Episode complete - max steps reached (1000)
[2026.01.08-01.31.46:123][ 80]LogTemp: Agent 3 (PlayerPawn_3): Episode complete - max steps reached (1000)
[2026.01.08-01.31.46:125][ 80]LogTemp: Agent 4 (PlayerPawn_4): Episode complete - max steps reached (1000)
[2026.01.08-01.31.46:125][ 80]LogTemp: Agent 5 (PlayerPawn_5): Episode complete - max steps reached (1000)
[2026.01.08-01.31.46:127][ 80]LogTemp: Agent 6 (PlayerPawn_6): Episode complete - max steps reached (1000)
[2026.01.08-01.31.46:128][ 80]LogTemp: Agent 7 (PlayerPawn_7): Episode complete - max steps reached (1000)
[2026.01.08-01.31.46:130][ 80]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 4 5 6 7].
[2026.01.08-01.31.46:131][ 80]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.46:132][ 80]LogTemp: Reset Target for Agent 0 - Target: X=-1050.630 Y=1198.584 Z=100.000
[2026.01.08-01.31.46:133][ 80]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=-705.527 Y=-1684.927 Z=100.000, Distance to Target: 2904.088573
[2026.01.08-01.31.46:134][ 80]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.46:135][ 80]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=274.361 Y=739.341 Z=100.000, Distance to Target: 1402.321728
[2026.01.08-01.31.46:136][ 80]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.46:137][ 80]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=-1219.703 Y=-1191.870 Z=100.000, Distance to Target: 2396.425335
[2026.01.08-01.31.46:139][ 80]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.46:139][ 80]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=895.230 Y=253.853 Z=100.000, Distance to Target: 2163.073932
[2026.01.08-01.31.46:141][ 80]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.46:141][ 80]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=-1074.313 Y=1844.600 Z=100.000, Distance to Target: 646.449824
[2026.01.08-01.31.46:143][ 80]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.46:144][ 80]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=-1248.512 Y=1640.004 Z=100.000, Distance to Target: 483.744519
[2026.01.08-01.31.46:146][ 80]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.46:147][ 80]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=-1651.845 Y=-500.687 Z=100.000, Distance to Target: 1802.492507
[2026.01.08-01.31.46:149][ 80]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.46:151][ 80]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=-1971.923 Y=-936.491 Z=100.000, Distance to Target: 2325.365558
[2026.01.08-01.31.46:469][382]LogTemp: Agent 5 (PlayerPawn_5): Episode complete - reached target
[2026.01.08-01.31.46:485][382]LogTemp: Agent 5 reached target! Reward: 100.000000
[2026.01.08-01.31.46:487][382]LogLearning: Display: Learning Agents Manager: Resetting Agents [5].
[2026.01.08-01.31.46:489][382]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.46:490][382]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=387.524 Y=-1760.125 Z=100.000, Distance to Target: 3289.717780
[2026.01.08-01.31.46:547][439]LogTemp: Agent 4 (PlayerPawn_4): Episode complete - reached target
[2026.01.08-01.31.46:560][439]LogTemp: Agent 4 reached target! Reward: 100.000000
[2026.01.08-01.31.46:562][439]LogLearning: Display: Learning Agents Manager: Resetting Agents [4].
[2026.01.08-01.31.46:563][439]LogTemp: Health reset to: 100.0
[2026.01.08-01.31.46:564][439]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=-135.929 Y=1484.359 Z=100.000, Distance to Target: 958.303213
[2026.01.08-01.31.46:718][592]LogLearning: Display: Pushing Experience...
[2026.01.08-01.31.46:719][592]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.31.46:721][592]LogLearning: Display: Subprocess: Iter:     320 | Avg Rew: 0.76319 | Avg Rew Sum: 295.35297 | Avg Return: 69.45483 | Avg Episode Len: 454.54545 | Batch Size: 1
[2026.01.08-01.31.46:721][592]LogLearning: Display: Subprocess: INFO: Profile| Logging                        5ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.46:725][592]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.31.46:725][592]LogLearning: Display: Subprocess: Episode Num: 21 | Total Step Num: 10000
[2026.01.08-01.31.46:727][592]LogLearning: Display: Subprocess: INFO: Profile| Pull Experience             1721ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.46:727][592]LogLearning: Display: Subprocess: INFO: Profile| PPO load tensors               0ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.46:755][592]LogLearning: Display: Subprocess: INFO: Profile| PPO gae                       29ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.46:811][592]LogLearning: Display: Subprocess: INFO: Profile| PPO log prob                  56ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.31.46:866][592]LogLearning: Display: Subprocess: INFO: Profile| PPO create batches            54ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.32.24:591][592]LogLearning: Display: Subprocess: INFO: Profile| PPO train                  37726ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.32.24:591][592]LogLearning: Display: Subprocess: INFO: Profile| Training                   37866ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.32.24:593][592]LogLearning: Display: Subprocess: INFO: Setting latest networks in communicator... IDs: [0, 1, 2, 3] | Version: 384
[2026.01.08-01.32.24:596][592]LogLearning: Display: Pulling network...
[2026.01.08-01.32.24:603][592]LogLearning: Display: Pulling network...
[2026.01.08-01.32.24:606][592]LogLearning: Display: Pulling network...
[2026.01.08-01.32.24:610][592]LogLearning: Display: Pulling network...
[2026.01.08-01.32.24:611][592]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 4 5 6 7].
[2026.01.08-01.32.24:612][592]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.24:614][592]LogTemp: Reset Target for Agent 0 - Target: X=-181.829 Y=759.362 Z=100.000
[2026.01.08-01.32.24:616][592]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=-966.033 Y=-512.650 Z=100.000, Distance to Target: 1494.318632
[2026.01.08-01.32.24:618][592]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.24:619][592]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=1117.161 Y=1552.843 Z=100.000, Distance to Target: 1522.165363
[2026.01.08-01.32.24:621][592]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.24:624][592]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=560.625 Y=-1932.615 Z=100.000, Distance to Target: 2792.485768
[2026.01.08-01.32.24:625][592]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.24:627][592]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=1531.846 Y=-1544.053 Z=100.000, Distance to Target: 2870.958696
[2026.01.08-01.32.24:629][592]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.24:631][592]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=1916.623 Y=-1721.183 Z=100.000, Distance to Target: 3249.092818
[2026.01.08-01.32.24:632][592]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.24:634][592]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=-1369.854 Y=-1747.551 Z=100.000, Distance to Target: 2774.168696
[2026.01.08-01.32.24:636][592]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.24:637][592]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=386.059 Y=-104.679 Z=100.000, Distance to Target: 1033.954720
[2026.01.08-01.32.24:640][592]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.24:641][592]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=-1098.849 Y=1492.416 Z=100.000, Distance to Target: 1174.008110
[2026.01.08-01.32.25:339][173]LogTemp: Agent 6 (PlayerPawn_6): Episode complete - reached target
[2026.01.08-01.32.25:341][173]LogTemp: Agent 6 reached target! Reward: 100.000000
[2026.01.08-01.32.25:342][173]LogLearning: Display: Learning Agents Manager: Resetting Agents [6].
[2026.01.08-01.32.25:343][173]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.25:345][173]LogTemp: Reset Agent 6 (PlayerPawn_6) - Character: X=265.816 Y=-1814.936 Z=100.000, Distance to Target: 2612.928039
[2026.01.08-01.32.25:468][288]LogTemp: Agent 7 (PlayerPawn_7): Episode complete - reached target
[2026.01.08-01.32.25:468][288]LogTemp: Agent 7 reached target! Reward: 100.000000
[2026.01.08-01.32.25:470][288]LogLearning: Display: Learning Agents Manager: Resetting Agents [7].
[2026.01.08-01.32.25:472][288]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.25:474][288]LogTemp: Reset Agent 7 (PlayerPawn_7) - Character: X=-1934.690 Y=-1562.120 Z=100.000, Distance to Target: 2908.917373
[2026.01.08-01.32.25:787][593]LogTemp: Agent 0 (PlayerPawn_0): Episode complete - max steps reached (1000)
[2026.01.08-01.32.25:788][593]LogTemp: Agent 1 (PlayerPawn_1): Episode complete - max steps reached (1000)
[2026.01.08-01.32.25:790][593]LogTemp: Agent 2 (PlayerPawn_2): Episode complete - max steps reached (1000)
[2026.01.08-01.32.25:792][593]LogTemp: Agent 3 (PlayerPawn_3): Episode complete - max steps reached (1000)
[2026.01.08-01.32.25:794][593]LogTemp: Agent 4 (PlayerPawn_4): Episode complete - max steps reached (1000)
[2026.01.08-01.32.25:796][593]LogTemp: Agent 5 (PlayerPawn_5): Episode complete - max steps reached (1000)
[2026.01.08-01.32.25:798][593]LogLearning: Display: Learning Agents Manager: Resetting Agents [0 1 2 3 4 5].
[2026.01.08-01.32.25:798][593]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.25:801][593]LogTemp: Reset Target for Agent 0 - Target: X=-292.184 Y=1664.052 Z=100.000
[2026.01.08-01.32.25:802][593]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=497.025 Y=1138.768 Z=100.000, Distance to Target: 948.037087
[2026.01.08-01.32.25:803][593]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.25:804][593]LogTemp: Reset Agent 1 (PlayerPawn_1) - Character: X=-634.602 Y=-130.192 Z=100.000, Distance to Target: 1826.625838
[2026.01.08-01.32.25:806][593]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.25:806][593]LogTemp: Reset Agent 2 (PlayerPawn_2) - Character: X=-1424.177 Y=665.487 Z=100.000, Distance to Target: 1509.483510
[2026.01.08-01.32.25:808][593]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.25:808][593]LogTemp: Reset Agent 3 (PlayerPawn_3) - Character: X=1177.465 Y=1086.154 Z=100.000, Distance to Target: 1579.188443
[2026.01.08-01.32.25:810][593]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.25:811][593]LogTemp: Reset Agent 4 (PlayerPawn_4) - Character: X=1665.029 Y=-901.944 Z=100.000, Distance to Target: 3227.230989
[2026.01.08-01.32.25:813][593]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.25:813][593]LogTemp: Reset Agent 5 (PlayerPawn_5) - Character: X=-962.126 Y=-743.614 Z=100.000, Distance to Target: 2499.135689
[2026.01.08-01.32.26:306][ 60]LogTemp: Agent 0 (PlayerPawn_0): Episode complete - reached target
[2026.01.08-01.32.26:308][ 60]LogTemp: Agent 0 reached target! Reward: 100.000000
[2026.01.08-01.32.26:309][ 60]LogLearning: Display: Learning Agents Manager: Resetting Agents [0].
[2026.01.08-01.32.26:311][ 60]LogTemp: Health reset to: 100.0
[2026.01.08-01.32.26:311][ 60]LogTemp: Reset Target for Agent 0 - Target: X=1854.732 Y=96.744 Z=100.000
[2026.01.08-01.32.26:313][ 60]LogTemp: Reset Agent 0 (PlayerPawn_0) - Character: X=-1780.389 Y=1277.200 Z=100.000, Distance to Target: 3821.986128
[2026.01.08-01.32.26:359][105]LogLearning: Display: Pushing Experience...
[2026.01.08-01.32.26:361][105]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.32.26:362][105]LogLearning: Display: Subprocess: Iter:     384 | Avg Rew: 0.70108 | Avg Rew Sum: 329.89190 | Avg Return: 71.91817 | Avg Episode Len: 476.19048 | Batch Size: 1
[2026.01.08-01.32.26:364][105]LogLearning: Display: Subprocess: INFO: Profile| Logging                       10ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.32.26:367][105]LogLearning: Display: Subprocess: INFO: 
[2026.01.08-01.32.26:369][105]LogLearning: Display: Subprocess: Episode Num: 22 | Total Step Num: 10000
[2026.01.08-01.32.26:371][105]LogLearning: Display: Subprocess: INFO: Profile| Pull Experience             1748ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.32.26:372][105]LogLearning: Display: Subprocess: INFO: Profile| PPO load tensors               0ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.32.26:396][105]LogLearning: Display: Subprocess: INFO: Profile| PPO gae                       28ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.32.26:449][105]LogLearning: Display: Subprocess: INFO: Profile| PPO log prob                  53ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
[2026.01.08-01.32.26:506][105]LogLearning: Display: Subprocess: INFO: Profile| PPO create batches            57ms   GPU Usage| Allocated: 0.00 GiB, Reserved: 0.00 GiB
